{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vieira_2006_HC_Melhorado_Eu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrskAWWKeOySoc5ZpnvyfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muriloufu/Hydrocyclone_ANN/blob/main/Vieira_2006_HC_Melhorado_Eu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOID4YHpNewq"
      },
      "source": [
        "#bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHeAwtRNnC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "cc816260-ed75-4965-c1fa-96752465d432"
      },
      "source": [
        "#selecao do dataset\n",
        "path = 'https://github.com/muriloufu/Hydrocyclone_ANN/raw/main/Tese_LG_2006_01.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "df"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>28.28</td>\n",
              "      <td>4493</td>\n",
              "      <td>65.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.30</td>\n",
              "      <td>4407</td>\n",
              "      <td>61.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>31.80</td>\n",
              "      <td>3997</td>\n",
              "      <td>72.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.20</td>\n",
              "      <td>3664</td>\n",
              "      <td>62.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>3697</td>\n",
              "      <td>54.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>10.50</td>\n",
              "      <td>3211</td>\n",
              "      <td>47.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>15.04</td>\n",
              "      <td>3257</td>\n",
              "      <td>61.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>17.16</td>\n",
              "      <td>3016</td>\n",
              "      <td>54.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>29.00</td>\n",
              "      <td>2416</td>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1789</td>\n",
              "      <td>69.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>32.68</td>\n",
              "      <td>1587</td>\n",
              "      <td>72.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.72</td>\n",
              "      <td>1467</td>\n",
              "      <td>63.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1679</td>\n",
              "      <td>68.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>14.10</td>\n",
              "      <td>1177</td>\n",
              "      <td>59.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>16.54</td>\n",
              "      <td>1071</td>\n",
              "      <td>62.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>16.19</td>\n",
              "      <td>1001</td>\n",
              "      <td>56.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.61</td>\n",
              "      <td>6435</td>\n",
              "      <td>62.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.7</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1109</td>\n",
              "      <td>60.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>42.54</td>\n",
              "      <td>2866</td>\n",
              "      <td>76.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.3</td>\n",
              "      <td>10.5</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>12.43</td>\n",
              "      <td>1671</td>\n",
              "      <td>66.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>117</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.65</td>\n",
              "      <td>2744</td>\n",
              "      <td>55.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>228</td>\n",
              "      <td>14.5</td>\n",
              "      <td>20.11</td>\n",
              "      <td>1525</td>\n",
              "      <td>49.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.22</td>\n",
              "      <td>2245</td>\n",
              "      <td>63.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.96</td>\n",
              "      <td>1801</td>\n",
              "      <td>61.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.31</td>\n",
              "      <td>1894</td>\n",
              "      <td>62.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1904</td>\n",
              "      <td>62.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.74</td>\n",
              "      <td>1889</td>\n",
              "      <td>68.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1818</td>\n",
              "      <td>69.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.90</td>\n",
              "      <td>1971</td>\n",
              "      <td>58.59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Di    Do    L  Teta     RL    Eu   Etta\n",
              "0   4.8   6.6  142  11.2  28.28  4493  65.18\n",
              "1   4.8   6.6  142  17.8  29.30  4407  61.76\n",
              "2   4.8   6.6  207  11.2  31.80  3997  72.47\n",
              "3   4.8   6.6  207  17.8  31.20  3664  62.23\n",
              "4   4.8   9.6  142  11.2  10.24  3697  54.06\n",
              "5   4.8   9.6  142  17.8  10.50  3211  47.30\n",
              "6   4.8   9.6  207  11.2  15.04  3257  61.52\n",
              "7   4.8   9.6  207  17.8  17.16  3016  54.30\n",
              "8   7.8   6.6  142  11.2  29.00  2416  74.59\n",
              "9   7.8   6.6  142  17.8  33.00  1789  69.00\n",
              "10  7.8   6.6  207  11.2  32.68  1587  72.32\n",
              "11  7.8   6.6  207  17.8  31.72  1467  63.40\n",
              "12  7.8   9.6  142  11.2  11.00  1679  68.82\n",
              "13  7.8   9.6  142  17.8  14.10  1177  59.83\n",
              "14  7.8   9.6  207  11.2  16.54  1071  62.42\n",
              "15  7.8   9.6  207  17.8  16.19  1001  56.44\n",
              "16  3.9   8.1  174  14.5  15.61  6435  62.84\n",
              "17  8.7   8.1  174  14.5  18.90  1109  60.35\n",
              "18  6.3   5.7  174  14.5  42.54  2866  76.73\n",
              "19  6.3  10.5  174  14.5  12.43  1671  66.00\n",
              "20  6.3   8.1  117  14.5  15.65  2744  55.61\n",
              "21  6.3   8.1  228  14.5  20.11  1525  49.17\n",
              "22  6.3   8.1  174   9.0  20.22  2245  63.44\n",
              "23  6.3   8.1  174  20.0  16.96  1801  61.14\n",
              "24  6.3   8.1  174  14.5  17.31  1894  62.31\n",
              "25  6.3   8.1  174  14.5  17.50  1904  62.74\n",
              "26  6.3   8.1  174  14.5  17.74  1889  68.24\n",
              "27  6.3   8.1  174  14.5  17.50  1818  69.49\n",
              "28  6.3   8.1  174  14.5  17.90  1971  58.59"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_18br6NreR"
      },
      "source": [
        "# funcao normatiza dados\n",
        "def Normatiza(x):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x[i].max()\n",
        "        min_x=x[i].min()\n",
        "        x[i]=2*((x[i]-min_x)/(max_x-min_x))-1\n",
        "    return x"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6NFycRWNtEI"
      },
      "source": [
        "# funcao retorna os dados a forma original - xi ISOLADO DA FUNCAO: NORMATIZA(X)\n",
        "def Original(x,x_old):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x_old[i].max()\n",
        "        min_x=x_old[i].min()\n",
        "        x[i]=((x[i]+1)/2)*(max_x-min_x)+min_x\n",
        "    return x"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRm1LcrNuMk"
      },
      "source": [
        "DAT_OLD=[] #Criar um dataframe em branco\n",
        "DAT_OLD=df.copy() #No dataframe em branco esta colocando os dados de df (dataframe que chamou no inicio)\n",
        "DAT=Normatiza(df) #No dataframe DAT coloca o dataframe df normatizado"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "iWlBoKYCCTZD",
        "outputId": "23c6cc2e-8057-40d1-e398-23ba0423d00e"
      },
      "source": [
        "DAT #mostra o dataframe DAT que Ã© o df normatizado"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.117028</td>\n",
              "      <td>0.285241</td>\n",
              "      <td>0.215087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.180186</td>\n",
              "      <td>0.253589</td>\n",
              "      <td>-0.017329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.334985</td>\n",
              "      <td>0.102687</td>\n",
              "      <td>0.710499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.297833</td>\n",
              "      <td>-0.019875</td>\n",
              "      <td>0.014611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.540605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.983901</td>\n",
              "      <td>-0.186603</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.702786</td>\n",
              "      <td>-0.169672</td>\n",
              "      <td>-0.033639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.571517</td>\n",
              "      <td>-0.258373</td>\n",
              "      <td>-0.524295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.161610</td>\n",
              "      <td>-0.479205</td>\n",
              "      <td>0.854570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.409288</td>\n",
              "      <td>-0.709974</td>\n",
              "      <td>0.474686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>-0.784321</td>\n",
              "      <td>0.700306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.330031</td>\n",
              "      <td>-0.828487</td>\n",
              "      <td>0.094122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.952941</td>\n",
              "      <td>-0.750460</td>\n",
              "      <td>0.462453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.760991</td>\n",
              "      <td>-0.935223</td>\n",
              "      <td>-0.148488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.609907</td>\n",
              "      <td>-0.974236</td>\n",
              "      <td>0.027523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.631579</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.378865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.667492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.056065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.463777</td>\n",
              "      <td>-0.960250</td>\n",
              "      <td>-0.113150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.313581</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.864396</td>\n",
              "      <td>-0.753404</td>\n",
              "      <td>0.270812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.665015</td>\n",
              "      <td>-0.358484</td>\n",
              "      <td>-0.435270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.388854</td>\n",
              "      <td>-0.807140</td>\n",
              "      <td>-0.872919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.382043</td>\n",
              "      <td>-0.542142</td>\n",
              "      <td>0.096840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.583901</td>\n",
              "      <td>-0.705558</td>\n",
              "      <td>-0.059463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.562229</td>\n",
              "      <td>-0.671329</td>\n",
              "      <td>0.020048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.667648</td>\n",
              "      <td>0.049269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.535604</td>\n",
              "      <td>-0.673169</td>\n",
              "      <td>0.423038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.699301</td>\n",
              "      <td>0.507985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.525697</td>\n",
              "      <td>-0.642989</td>\n",
              "      <td>-0.232756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Di            Do         L  Teta        RL        Eu      Etta\n",
              "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.117028  0.285241  0.215087\n",
              "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6  0.180186  0.253589 -0.017329\n",
              "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6  0.334985  0.102687  0.710499\n",
              "3  -6.250000e-01 -6.250000e-01  0.621622   0.6  0.297833 -0.019875  0.014611\n",
              "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6 -1.000000 -0.007729 -0.540605\n",
              "5  -6.250000e-01  6.250000e-01 -0.549550   0.6 -0.983901 -0.186603 -1.000000\n",
              "6  -6.250000e-01  6.250000e-01  0.621622  -0.6 -0.702786 -0.169672 -0.033639\n",
              "7  -6.250000e-01  6.250000e-01  0.621622   0.6 -0.571517 -0.258373 -0.524295\n",
              "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.161610 -0.479205  0.854570\n",
              "9   6.250000e-01 -6.250000e-01 -0.549550   0.6  0.409288 -0.709974  0.474686\n",
              "10  6.250000e-01 -6.250000e-01  0.621622  -0.6  0.389474 -0.784321  0.700306\n",
              "11  6.250000e-01 -6.250000e-01  0.621622   0.6  0.330031 -0.828487  0.094122\n",
              "12  6.250000e-01  6.250000e-01 -0.549550  -0.6 -0.952941 -0.750460  0.462453\n",
              "13  6.250000e-01  6.250000e-01 -0.549550   0.6 -0.760991 -0.935223 -0.148488\n",
              "14  6.250000e-01  6.250000e-01  0.621622  -0.6 -0.609907 -0.974236  0.027523\n",
              "15  6.250000e-01  6.250000e-01  0.621622   0.6 -0.631579 -1.000000 -0.378865\n",
              "16 -1.000000e+00 -2.220446e-16  0.027027   0.0 -0.667492  1.000000  0.056065\n",
              "17  1.000000e+00 -2.220446e-16  0.027027   0.0 -0.463777 -0.960250 -0.113150\n",
              "18  2.220446e-16 -1.000000e+00  0.027027   0.0  1.000000 -0.313581  1.000000\n",
              "19  2.220446e-16  1.000000e+00  0.027027   0.0 -0.864396 -0.753404  0.270812\n",
              "20  2.220446e-16 -2.220446e-16 -1.000000   0.0 -0.665015 -0.358484 -0.435270\n",
              "21  2.220446e-16 -2.220446e-16  1.000000   0.0 -0.388854 -0.807140 -0.872919\n",
              "22  2.220446e-16 -2.220446e-16  0.027027  -1.0 -0.382043 -0.542142  0.096840\n",
              "23  2.220446e-16 -2.220446e-16  0.027027   1.0 -0.583901 -0.705558 -0.059463\n",
              "24  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.562229 -0.671329  0.020048\n",
              "25  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.667648  0.049269\n",
              "26  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.535604 -0.673169  0.423038\n",
              "27  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.699301  0.507985\n",
              "28  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.525697 -0.642989 -0.232756"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHAmeF3u9b1v"
      },
      "source": [
        "#dividindo randomicamente os dados de DAT em treino e teste\n",
        "train=DAT.sample(frac=0.8,random_state=None)\n",
        "test=DAT.drop(train.index)"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3NrCwW9mUU"
      },
      "source": [
        "#Definindo as variaveis independentes\n",
        "x_train=train.iloc[:,[0,1,2,3]]\n",
        "x_test=test.iloc[:,[0,1,2,3]]\n",
        "X_OLD=DAT_OLD.iloc[:,[0,1,2,3]]"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHep1do94DF",
        "outputId": "5a0d01b0-a115-4cc8-ecdf-3817f3918586"
      },
      "source": [
        "#variaveis independentes de treino e teste\n",
        "print(x_train)\n",
        "print (x_test)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Di            Do         L  Teta\n",
            "10  6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "13  6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "6  -6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "27  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "17  1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "22  2.220446e-16 -2.220446e-16  0.027027  -1.0\n",
            "24  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "12  6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "21  2.220446e-16 -2.220446e-16  1.000000   0.0\n",
            "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "28  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "9   6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "7  -6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "20  2.220446e-16 -2.220446e-16 -1.000000   0.0\n",
            "23  2.220446e-16 -2.220446e-16  0.027027   1.0\n",
            "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "5  -6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "19  2.220446e-16  1.000000e+00  0.027027   0.0\n",
            "14  6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "16 -1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "              Di            Do         L  Teta\n",
            "3  -6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "11  6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "15  6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "18  2.220446e-16 -1.000000e+00  0.027027   0.0\n",
            "25  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "26  2.220446e-16 -2.220446e-16  0.027027   0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4vJ0_69yiE",
        "outputId": "fdadfa98-bf76-44a2-fe03-5fdefa1f8eac"
      },
      "source": [
        "#definindo a variavel dependente RL\n",
        "y_train=train.iloc[:,[5]]\n",
        "y_test=test.iloc[:,[5]]\n",
        "Y_OLD=DAT_OLD.iloc[:,[5]]\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Eu\n",
            "10 -0.784321\n",
            "13 -0.935223\n",
            "6  -0.169672\n",
            "27 -0.699301\n",
            "17 -0.960250\n",
            "22 -0.542142\n",
            "24 -0.671329\n",
            "12 -0.750460\n",
            "1   0.253589\n",
            "21 -0.807140\n",
            "8  -0.479205\n",
            "28 -0.642989\n",
            "2   0.102687\n",
            "9  -0.709974\n",
            "7  -0.258373\n",
            "20 -0.358484\n",
            "23 -0.705558\n",
            "0   0.285241\n",
            "4  -0.007729\n",
            "5  -0.186603\n",
            "19 -0.753404\n",
            "14 -0.974236\n",
            "16  1.000000\n",
            "          Eu\n",
            "3  -0.019875\n",
            "11 -0.828487\n",
            "15 -1.000000\n",
            "18 -0.313581\n",
            "25 -0.667648\n",
            "26 -0.673169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4haSAcEPN2S7"
      },
      "source": [
        "#define a rede neural\n",
        "#nessa rede vao ser usados 3 camadas: Input + hidden + output\n",
        "#o numero de neuronios da output eh 1, porque tem 1 resposta (FIE)\n",
        "#o numero de neuronios na hidden eh arbitrario. O artigo fez 12 neuronios nessa camada\n",
        "#funcao de ativicao eh a logistic, segundo o artigo\n",
        "model = MLPRegressor(random_state=1,solver='lbfgs',activation='tanh', learning_rate = 'adaptive', alpha=1e-5, \n",
        "                     hidden_layer_sizes= tuple(100 for _ in range(10)))"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhi90gVN3YV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d12643-209d-4170-f273-6ab15da768f3"
      },
      "source": [
        "#treina a rede neural\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "             hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                                 100),\n",
              "             learning_rate='adaptive', learning_rate_init=0.001, max_fun=15000,\n",
              "             max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
              "             solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-yOW0ZmN4e0"
      },
      "source": [
        "#usa a rede neural para treino e teste\n",
        "y_calc_train=model.predict(x_train)\n",
        "y_calc_test=model.predict(x_test)"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfwjcMtN58a"
      },
      "source": [
        "#transforma a saida da rede em dataframe \n",
        "y_calc_train=pd.DataFrame(y_calc_train)\n",
        "y_calc_test=pd.DataFrame(y_calc_test)\n",
        "col_names=list(y_train)\n",
        "y_calc_train.columns = col_names\n",
        "y_calc_test.columns = col_names"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RboALKIN7as"
      },
      "source": [
        "#Desnormatizar os dados obtidos da rede neural\n",
        "y_calc_train=Original(y_calc_train,Y_OLD)\n",
        "y_calc_test=Original(y_calc_test,Y_OLD)"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjoCPU8bN92O"
      },
      "source": [
        "#recupera os dados originais \n",
        "test=[]\n",
        "train=[]\n",
        "train=Original(y_train,Y_OLD)\n",
        "test=Original(y_test,Y_OLD)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiL9upNxN_RT"
      },
      "source": [
        "#Resposta para fazer o grafico (Eu-treino)\n",
        "resist_obs_train=[]\n",
        "resist_calc_train=[]\n",
        "resist_calc_train=y_calc_train['Eu'].copy()\n",
        "resist_obs_train=train['Eu'].copy()"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_g9O8DOAfQ"
      },
      "source": [
        "#Resposta para fazer o grafico (Eu-teste)\n",
        "resist_obs_test=[]\n",
        "resist_calc_test=[]\n",
        "resist_calc_test=y_calc_test['Eu'].copy()\n",
        "resist_obs_test=test['Eu'].copy()"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHCXQdoOBtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "eb433e2c-0b20-4964-8be2-84c2837dd2c6"
      },
      "source": [
        "#expressa os dois dados em figura - EULER\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.scatter(resist_obs_test,resist_calc_test, s=10, c='b', marker=\"s\", label='teste')\n",
        "ax1.scatter(resist_obs_train,resist_calc_train, s=10, c='r', marker=\"o\", label='treino')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylabel('Eu')\n",
        "plt.xlabel('Eu')\n",
        "plt.show()"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxqGLrm6OCHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deab38d8-b5dc-4daf-ab2f-6d8fb4f8621e"
      },
      "source": [
        "#checar a qualidade da regressao PARA TESTE\n",
        "mse=mean_squared_error(resist_obs_test,resist_calc_test)\n",
        "print(\"MSE teste=\",mse)\n",
        "R2=r2_score(resist_obs_test,resist_calc_test)\n",
        "print(\"R^2 teste=\",R2)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE teste= 34976.92448694697\n",
            "R^2 teste= 0.9555208344677967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEznkoupODnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3d9eb1-f790-42dd-9d99-591abf110c96"
      },
      "source": [
        "#checar a qualidade da regressao PARA TREINO\n",
        "mse=mean_squared_error(resist_obs_train,resist_calc_train)\n",
        "print(\"MSE treino=\",mse)\n",
        "R2=r2_score(resist_obs_train,resist_calc_train)\n",
        "print(\"R^2 treino=\",R2)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE treino= 622.858497967041\n",
            "R^2 treino= 0.9996338289721466\n"
          ]
        }
      ]
    }
  ]
}