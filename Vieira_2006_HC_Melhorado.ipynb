{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vieira_2006_HC_Melhorado.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8oBnembPROcNpUBDI4LRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muriloufu/Hydrocyclone_ANN/blob/main/Vieira_2006_HC_Melhorado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOID4YHpNewq"
      },
      "source": [
        "#bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files"
      ],
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHeAwtRNnC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "dadefdd8-5314-4565-c108-8f9d454b7b12"
      },
      "source": [
        "#selecao do dataset\n",
        "path = 'https://github.com/muriloufu/Hydrocyclone_ANN/raw/main/Tese_LG_2006_01.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "df"
      ],
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>28.28</td>\n",
              "      <td>4493</td>\n",
              "      <td>65.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.30</td>\n",
              "      <td>4407</td>\n",
              "      <td>61.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>31.80</td>\n",
              "      <td>3997</td>\n",
              "      <td>72.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.20</td>\n",
              "      <td>3664</td>\n",
              "      <td>62.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>3697</td>\n",
              "      <td>54.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>10.50</td>\n",
              "      <td>3211</td>\n",
              "      <td>47.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>15.04</td>\n",
              "      <td>3257</td>\n",
              "      <td>61.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>17.16</td>\n",
              "      <td>3016</td>\n",
              "      <td>54.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>29.00</td>\n",
              "      <td>2416</td>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1789</td>\n",
              "      <td>69.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>32.68</td>\n",
              "      <td>1587</td>\n",
              "      <td>72.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.72</td>\n",
              "      <td>1467</td>\n",
              "      <td>63.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1679</td>\n",
              "      <td>68.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>14.10</td>\n",
              "      <td>1177</td>\n",
              "      <td>59.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>16.54</td>\n",
              "      <td>1071</td>\n",
              "      <td>62.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>16.19</td>\n",
              "      <td>1001</td>\n",
              "      <td>56.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.61</td>\n",
              "      <td>6435</td>\n",
              "      <td>62.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.7</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1109</td>\n",
              "      <td>60.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>42.54</td>\n",
              "      <td>2866</td>\n",
              "      <td>76.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.3</td>\n",
              "      <td>10.5</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>12.43</td>\n",
              "      <td>1671</td>\n",
              "      <td>66.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>117</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.65</td>\n",
              "      <td>2744</td>\n",
              "      <td>55.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>228</td>\n",
              "      <td>14.5</td>\n",
              "      <td>20.11</td>\n",
              "      <td>1525</td>\n",
              "      <td>49.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.22</td>\n",
              "      <td>2245</td>\n",
              "      <td>63.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.96</td>\n",
              "      <td>1801</td>\n",
              "      <td>61.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.31</td>\n",
              "      <td>1894</td>\n",
              "      <td>62.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1904</td>\n",
              "      <td>62.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.74</td>\n",
              "      <td>1889</td>\n",
              "      <td>68.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1818</td>\n",
              "      <td>69.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.90</td>\n",
              "      <td>1971</td>\n",
              "      <td>58.59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Di    Do    L  Teta     RL    Eu   Etta\n",
              "0   4.8   6.6  142  11.2  28.28  4493  65.18\n",
              "1   4.8   6.6  142  17.8  29.30  4407  61.76\n",
              "2   4.8   6.6  207  11.2  31.80  3997  72.47\n",
              "3   4.8   6.6  207  17.8  31.20  3664  62.23\n",
              "4   4.8   9.6  142  11.2  10.24  3697  54.06\n",
              "5   4.8   9.6  142  17.8  10.50  3211  47.30\n",
              "6   4.8   9.6  207  11.2  15.04  3257  61.52\n",
              "7   4.8   9.6  207  17.8  17.16  3016  54.30\n",
              "8   7.8   6.6  142  11.2  29.00  2416  74.59\n",
              "9   7.8   6.6  142  17.8  33.00  1789  69.00\n",
              "10  7.8   6.6  207  11.2  32.68  1587  72.32\n",
              "11  7.8   6.6  207  17.8  31.72  1467  63.40\n",
              "12  7.8   9.6  142  11.2  11.00  1679  68.82\n",
              "13  7.8   9.6  142  17.8  14.10  1177  59.83\n",
              "14  7.8   9.6  207  11.2  16.54  1071  62.42\n",
              "15  7.8   9.6  207  17.8  16.19  1001  56.44\n",
              "16  3.9   8.1  174  14.5  15.61  6435  62.84\n",
              "17  8.7   8.1  174  14.5  18.90  1109  60.35\n",
              "18  6.3   5.7  174  14.5  42.54  2866  76.73\n",
              "19  6.3  10.5  174  14.5  12.43  1671  66.00\n",
              "20  6.3   8.1  117  14.5  15.65  2744  55.61\n",
              "21  6.3   8.1  228  14.5  20.11  1525  49.17\n",
              "22  6.3   8.1  174   9.0  20.22  2245  63.44\n",
              "23  6.3   8.1  174  20.0  16.96  1801  61.14\n",
              "24  6.3   8.1  174  14.5  17.31  1894  62.31\n",
              "25  6.3   8.1  174  14.5  17.50  1904  62.74\n",
              "26  6.3   8.1  174  14.5  17.74  1889  68.24\n",
              "27  6.3   8.1  174  14.5  17.50  1818  69.49\n",
              "28  6.3   8.1  174  14.5  17.90  1971  58.59"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_18br6NreR"
      },
      "source": [
        "# funcao normatiza dados\n",
        "def Normatiza(x):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x[i].max()\n",
        "        min_x=x[i].min()\n",
        "        x[i]=2*((x[i]-min_x)/(max_x-min_x))-1\n",
        "    return x"
      ],
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6NFycRWNtEI"
      },
      "source": [
        "# funcao retorna os dados a forma original - xi ISOLADO DA FUNCAO: NORMATIZA(X)\n",
        "def Original(x,x_old):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x_old[i].max()\n",
        "        min_x=x_old[i].min()\n",
        "        x[i]=((x[i]+1)/2)*(max_x-min_x)+min_x\n",
        "    return x"
      ],
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRm1LcrNuMk"
      },
      "source": [
        "DAT_OLD=[] #Criar um dataframe em branco\n",
        "DAT_OLD=df.copy() #No dataframe em branco esta colocando os dados de df (dataframe que chamou no inicio)\n",
        "DAT=Normatiza(df) #No dataframe DAT coloca o dataframe df normatizado"
      ],
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "iWlBoKYCCTZD",
        "outputId": "25d765fa-0c62-4245-8052-0874ee8af025"
      },
      "source": [
        "DAT #mostra o dataframe DAT que Ã© o df normatizado"
      ],
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.117028</td>\n",
              "      <td>0.285241</td>\n",
              "      <td>0.215087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.180186</td>\n",
              "      <td>0.253589</td>\n",
              "      <td>-0.017329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.334985</td>\n",
              "      <td>0.102687</td>\n",
              "      <td>0.710499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.297833</td>\n",
              "      <td>-0.019875</td>\n",
              "      <td>0.014611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.540605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.983901</td>\n",
              "      <td>-0.186603</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.702786</td>\n",
              "      <td>-0.169672</td>\n",
              "      <td>-0.033639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.571517</td>\n",
              "      <td>-0.258373</td>\n",
              "      <td>-0.524295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.161610</td>\n",
              "      <td>-0.479205</td>\n",
              "      <td>0.854570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.409288</td>\n",
              "      <td>-0.709974</td>\n",
              "      <td>0.474686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>-0.784321</td>\n",
              "      <td>0.700306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.330031</td>\n",
              "      <td>-0.828487</td>\n",
              "      <td>0.094122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.952941</td>\n",
              "      <td>-0.750460</td>\n",
              "      <td>0.462453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.760991</td>\n",
              "      <td>-0.935223</td>\n",
              "      <td>-0.148488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.609907</td>\n",
              "      <td>-0.974236</td>\n",
              "      <td>0.027523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.631579</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.378865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.667492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.056065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.463777</td>\n",
              "      <td>-0.960250</td>\n",
              "      <td>-0.113150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.313581</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.864396</td>\n",
              "      <td>-0.753404</td>\n",
              "      <td>0.270812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.665015</td>\n",
              "      <td>-0.358484</td>\n",
              "      <td>-0.435270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.388854</td>\n",
              "      <td>-0.807140</td>\n",
              "      <td>-0.872919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.382043</td>\n",
              "      <td>-0.542142</td>\n",
              "      <td>0.096840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.583901</td>\n",
              "      <td>-0.705558</td>\n",
              "      <td>-0.059463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.562229</td>\n",
              "      <td>-0.671329</td>\n",
              "      <td>0.020048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.667648</td>\n",
              "      <td>0.049269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.535604</td>\n",
              "      <td>-0.673169</td>\n",
              "      <td>0.423038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.699301</td>\n",
              "      <td>0.507985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.525697</td>\n",
              "      <td>-0.642989</td>\n",
              "      <td>-0.232756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Di            Do         L  Teta        RL        Eu      Etta\n",
              "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.117028  0.285241  0.215087\n",
              "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6  0.180186  0.253589 -0.017329\n",
              "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6  0.334985  0.102687  0.710499\n",
              "3  -6.250000e-01 -6.250000e-01  0.621622   0.6  0.297833 -0.019875  0.014611\n",
              "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6 -1.000000 -0.007729 -0.540605\n",
              "5  -6.250000e-01  6.250000e-01 -0.549550   0.6 -0.983901 -0.186603 -1.000000\n",
              "6  -6.250000e-01  6.250000e-01  0.621622  -0.6 -0.702786 -0.169672 -0.033639\n",
              "7  -6.250000e-01  6.250000e-01  0.621622   0.6 -0.571517 -0.258373 -0.524295\n",
              "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.161610 -0.479205  0.854570\n",
              "9   6.250000e-01 -6.250000e-01 -0.549550   0.6  0.409288 -0.709974  0.474686\n",
              "10  6.250000e-01 -6.250000e-01  0.621622  -0.6  0.389474 -0.784321  0.700306\n",
              "11  6.250000e-01 -6.250000e-01  0.621622   0.6  0.330031 -0.828487  0.094122\n",
              "12  6.250000e-01  6.250000e-01 -0.549550  -0.6 -0.952941 -0.750460  0.462453\n",
              "13  6.250000e-01  6.250000e-01 -0.549550   0.6 -0.760991 -0.935223 -0.148488\n",
              "14  6.250000e-01  6.250000e-01  0.621622  -0.6 -0.609907 -0.974236  0.027523\n",
              "15  6.250000e-01  6.250000e-01  0.621622   0.6 -0.631579 -1.000000 -0.378865\n",
              "16 -1.000000e+00 -2.220446e-16  0.027027   0.0 -0.667492  1.000000  0.056065\n",
              "17  1.000000e+00 -2.220446e-16  0.027027   0.0 -0.463777 -0.960250 -0.113150\n",
              "18  2.220446e-16 -1.000000e+00  0.027027   0.0  1.000000 -0.313581  1.000000\n",
              "19  2.220446e-16  1.000000e+00  0.027027   0.0 -0.864396 -0.753404  0.270812\n",
              "20  2.220446e-16 -2.220446e-16 -1.000000   0.0 -0.665015 -0.358484 -0.435270\n",
              "21  2.220446e-16 -2.220446e-16  1.000000   0.0 -0.388854 -0.807140 -0.872919\n",
              "22  2.220446e-16 -2.220446e-16  0.027027  -1.0 -0.382043 -0.542142  0.096840\n",
              "23  2.220446e-16 -2.220446e-16  0.027027   1.0 -0.583901 -0.705558 -0.059463\n",
              "24  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.562229 -0.671329  0.020048\n",
              "25  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.667648  0.049269\n",
              "26  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.535604 -0.673169  0.423038\n",
              "27  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.699301  0.507985\n",
              "28  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.525697 -0.642989 -0.232756"
            ]
          },
          "metadata": {},
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHAmeF3u9b1v"
      },
      "source": [
        "#dividindo randomicamente os dados de DAT em treino e teste\n",
        "train=DAT.sample(frac=0.8,random_state=None)\n",
        "test=DAT.drop(train.index)"
      ],
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3NrCwW9mUU"
      },
      "source": [
        "#Definindo as variaveis independentes\n",
        "x_train=train.iloc[:,[0,1,2,3]]\n",
        "x_test=test.iloc[:,[0,1,2,3]]\n",
        "X_OLD=DAT_OLD.iloc[:,[0,1,2,3]]"
      ],
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHep1do94DF",
        "outputId": "1a481f8c-2260-45d8-bcea-477c59188541"
      },
      "source": [
        "#variaveis independentes de treino e teste\n",
        "print(x_train)\n",
        "print (x_test)"
      ],
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Di            Do         L  Teta\n",
            "26  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "17  1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "24  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "20  2.220446e-16 -2.220446e-16 -1.000000   0.0\n",
            "19  2.220446e-16  1.000000e+00  0.027027   0.0\n",
            "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "21  2.220446e-16 -2.220446e-16  1.000000   0.0\n",
            "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "12  6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "14  6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "10  6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "3  -6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "6  -6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "27  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "13  6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "11  6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "15  6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "28  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "16 -1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "25  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "9   6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "              Di            Do         L  Teta\n",
            "5  -6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "7  -6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "18  2.220446e-16 -1.000000e+00  0.027027   0.0\n",
            "22  2.220446e-16 -2.220446e-16  0.027027  -1.0\n",
            "23  2.220446e-16 -2.220446e-16  0.027027   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4vJ0_69yiE",
        "outputId": "5173ca22-b4eb-4aa7-bcef-fee15659dacb"
      },
      "source": [
        "#definindo a variavel dependente RL\n",
        "y_train=train.iloc[:,[4]]\n",
        "y_test=test.iloc[:,[4]]\n",
        "Y_OLD=DAT_OLD.iloc[:,[4]]\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          RL\n",
            "26 -0.535604\n",
            "17 -0.463777\n",
            "24 -0.562229\n",
            "20 -0.665015\n",
            "19 -0.864396\n",
            "1   0.180186\n",
            "21 -0.388854\n",
            "2   0.334985\n",
            "12 -0.952941\n",
            "14 -0.609907\n",
            "10  0.389474\n",
            "3   0.297833\n",
            "4  -1.000000\n",
            "6  -0.702786\n",
            "27 -0.550464\n",
            "13 -0.760991\n",
            "11  0.330031\n",
            "15 -0.631579\n",
            "28 -0.525697\n",
            "16 -0.667492\n",
            "25 -0.550464\n",
            "9   0.409288\n",
            "0   0.117028\n",
            "          RL\n",
            "5  -0.983901\n",
            "7  -0.571517\n",
            "8   0.161610\n",
            "18  1.000000\n",
            "22 -0.382043\n",
            "23 -0.583901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4haSAcEPN2S7"
      },
      "source": [
        "#define a rede neural\n",
        "#nessa rede vao ser usados 3 camadas: Input + hidden + output\n",
        "#o numero de neuronios da output eh 1, porque tem 1 resposta (FIE)\n",
        "#o numero de neuronios na hidden eh arbitrario. O artigo fez 12 neuronios nessa camada\n",
        "#funcao de ativicao eh a logistic, segundo o artigo\n",
        "model = MLPRegressor(random_state=1,solver='lbfgs',activation='tanh', learning_rate = 'adaptive', alpha=1e-5, \n",
        "                     hidden_layer_sizes= tuple(100 for _ in range(5)))"
      ],
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhi90gVN3YV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2325500-8920-41b8-f4d8-6dceac5e97e8"
      },
      "source": [
        "#treina a rede neural\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "             hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
              "             learning_rate='adaptive', learning_rate_init=0.001, max_fun=15000,\n",
              "             max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
              "             solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-yOW0ZmN4e0"
      },
      "source": [
        "#usa a rede neural para treino e teste\n",
        "y_calc_train=model.predict(x_train)\n",
        "y_calc_test=model.predict(x_test)"
      ],
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfwjcMtN58a"
      },
      "source": [
        "#transforma a saida da rede em dataframe \n",
        "y_calc_train=pd.DataFrame(y_calc_train)\n",
        "y_calc_test=pd.DataFrame(y_calc_test)\n",
        "col_names=list(y_train)\n",
        "y_calc_train.columns = col_names\n",
        "y_calc_test.columns = col_names"
      ],
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RboALKIN7as"
      },
      "source": [
        "#Desnormatizar os dados obtidos da rede neural\n",
        "y_calc_train=Original(y_calc_train,Y_OLD)\n",
        "y_calc_test=Original(y_calc_test,Y_OLD)"
      ],
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjoCPU8bN92O"
      },
      "source": [
        "#recupera os dados originais \n",
        "test=[]\n",
        "train=[]\n",
        "train=Original(y_train,Y_OLD)\n",
        "test=Original(y_test,Y_OLD)"
      ],
      "execution_count": 428,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiL9upNxN_RT"
      },
      "source": [
        "#Resposta para fazer o grafico (FIE-treino)\n",
        "resist_obs_train=[]\n",
        "resist_calc_train=[]\n",
        "resist_calc_train=y_calc_train['RL'].copy()\n",
        "resist_obs_train=train['RL'].copy()"
      ],
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_g9O8DOAfQ"
      },
      "source": [
        "#Resposta para fazer o grafico (FIE-teste)\n",
        "resist_obs_test=[]\n",
        "resist_calc_test=[]\n",
        "resist_calc_test=y_calc_test['RL'].copy()\n",
        "resist_obs_test=test['RL'].copy()"
      ],
      "execution_count": 430,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHCXQdoOBtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5e828f40-377d-47f1-a7cd-eb5c5485f1cf"
      },
      "source": [
        "#expressa os dois dados em figura - EULER\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.scatter(resist_obs_test,resist_calc_test, s=10, c='b', marker=\"s\", label='teste')\n",
        "ax1.scatter(resist_obs_train,resist_calc_train, s=10, c='r', marker=\"o\", label='treino')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylabel('FIE Calc')\n",
        "plt.xlabel('FIE Obs')\n",
        "plt.show()"
      ],
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxqGLrm6OCHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714f3393-0a36-44ad-db0d-a83d626b22e1"
      },
      "source": [
        "#checar a qualidade da regressao PARA TESTE\n",
        "mse=mean_squared_error(resist_obs_test,resist_calc_test)\n",
        "print(\"MSE teste=\",mse)\n",
        "R2=r2_score(resist_obs_test,resist_calc_test)\n",
        "print(\"R^2 teste=\",R2)"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE teste= 5.8100313213522945\n",
            "R^2 teste= 0.9465285170070706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEznkoupODnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b236bc4-737d-48f7-ff42-fb0dc366d314"
      },
      "source": [
        "#checar a qualidade da regressao PARA TREINO\n",
        "mse=mean_squared_error(resist_obs_train,resist_calc_train)\n",
        "print(\"MSE treino=\",mse)\n",
        "R2=r2_score(resist_obs_train,resist_calc_train)\n",
        "print(\"R^2 treino=\",R2)"
      ],
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE treino= 0.013151960730119774\n",
            "R^2 treino= 0.9997616288602632\n"
          ]
        }
      ]
    }
  ]
}