{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vieira_2006_HC_Melhorado.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPl0jK9BNNYuJkN1pAVYYoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muriloufu/Hydrocyclone_ANN/blob/main/Vieira_2006_HC_Melhorado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOID4YHpNewq"
      },
      "source": [
        "#bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files"
      ],
      "execution_count": 623,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHeAwtRNnC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "af56ef94-846d-44c7-f1be-712ce50ec4ec"
      },
      "source": [
        "#selecao do dataset\n",
        "path = 'https://github.com/muriloufu/Hydrocyclone_ANN/raw/main/Tese_LG_2006_01.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "df"
      ],
      "execution_count": 624,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>28.28</td>\n",
              "      <td>4493</td>\n",
              "      <td>65.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.30</td>\n",
              "      <td>4407</td>\n",
              "      <td>61.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>31.80</td>\n",
              "      <td>3997</td>\n",
              "      <td>72.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.20</td>\n",
              "      <td>3664</td>\n",
              "      <td>62.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>3697</td>\n",
              "      <td>54.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>10.50</td>\n",
              "      <td>3211</td>\n",
              "      <td>47.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>15.04</td>\n",
              "      <td>3257</td>\n",
              "      <td>61.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>17.16</td>\n",
              "      <td>3016</td>\n",
              "      <td>54.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>29.00</td>\n",
              "      <td>2416</td>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1789</td>\n",
              "      <td>69.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>32.68</td>\n",
              "      <td>1587</td>\n",
              "      <td>72.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.72</td>\n",
              "      <td>1467</td>\n",
              "      <td>63.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1679</td>\n",
              "      <td>68.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>14.10</td>\n",
              "      <td>1177</td>\n",
              "      <td>59.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>16.54</td>\n",
              "      <td>1071</td>\n",
              "      <td>62.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>16.19</td>\n",
              "      <td>1001</td>\n",
              "      <td>56.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.61</td>\n",
              "      <td>6435</td>\n",
              "      <td>62.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.7</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1109</td>\n",
              "      <td>60.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>42.54</td>\n",
              "      <td>2866</td>\n",
              "      <td>76.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.3</td>\n",
              "      <td>10.5</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>12.43</td>\n",
              "      <td>1671</td>\n",
              "      <td>66.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>117</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.65</td>\n",
              "      <td>2744</td>\n",
              "      <td>55.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>228</td>\n",
              "      <td>14.5</td>\n",
              "      <td>20.11</td>\n",
              "      <td>1525</td>\n",
              "      <td>49.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.22</td>\n",
              "      <td>2245</td>\n",
              "      <td>63.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.96</td>\n",
              "      <td>1801</td>\n",
              "      <td>61.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.31</td>\n",
              "      <td>1894</td>\n",
              "      <td>62.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1904</td>\n",
              "      <td>62.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.74</td>\n",
              "      <td>1889</td>\n",
              "      <td>68.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1818</td>\n",
              "      <td>69.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.90</td>\n",
              "      <td>1971</td>\n",
              "      <td>58.59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Di    Do    L  Teta     RL    Eu   Etta\n",
              "0   4.8   6.6  142  11.2  28.28  4493  65.18\n",
              "1   4.8   6.6  142  17.8  29.30  4407  61.76\n",
              "2   4.8   6.6  207  11.2  31.80  3997  72.47\n",
              "3   4.8   6.6  207  17.8  31.20  3664  62.23\n",
              "4   4.8   9.6  142  11.2  10.24  3697  54.06\n",
              "5   4.8   9.6  142  17.8  10.50  3211  47.30\n",
              "6   4.8   9.6  207  11.2  15.04  3257  61.52\n",
              "7   4.8   9.6  207  17.8  17.16  3016  54.30\n",
              "8   7.8   6.6  142  11.2  29.00  2416  74.59\n",
              "9   7.8   6.6  142  17.8  33.00  1789  69.00\n",
              "10  7.8   6.6  207  11.2  32.68  1587  72.32\n",
              "11  7.8   6.6  207  17.8  31.72  1467  63.40\n",
              "12  7.8   9.6  142  11.2  11.00  1679  68.82\n",
              "13  7.8   9.6  142  17.8  14.10  1177  59.83\n",
              "14  7.8   9.6  207  11.2  16.54  1071  62.42\n",
              "15  7.8   9.6  207  17.8  16.19  1001  56.44\n",
              "16  3.9   8.1  174  14.5  15.61  6435  62.84\n",
              "17  8.7   8.1  174  14.5  18.90  1109  60.35\n",
              "18  6.3   5.7  174  14.5  42.54  2866  76.73\n",
              "19  6.3  10.5  174  14.5  12.43  1671  66.00\n",
              "20  6.3   8.1  117  14.5  15.65  2744  55.61\n",
              "21  6.3   8.1  228  14.5  20.11  1525  49.17\n",
              "22  6.3   8.1  174   9.0  20.22  2245  63.44\n",
              "23  6.3   8.1  174  20.0  16.96  1801  61.14\n",
              "24  6.3   8.1  174  14.5  17.31  1894  62.31\n",
              "25  6.3   8.1  174  14.5  17.50  1904  62.74\n",
              "26  6.3   8.1  174  14.5  17.74  1889  68.24\n",
              "27  6.3   8.1  174  14.5  17.50  1818  69.49\n",
              "28  6.3   8.1  174  14.5  17.90  1971  58.59"
            ]
          },
          "metadata": {},
          "execution_count": 624
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_18br6NreR"
      },
      "source": [
        "# funcao normatiza dados\n",
        "def Normatiza(x):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x[i].max()\n",
        "        min_x=x[i].min()\n",
        "        x[i]=2*((x[i]-min_x)/(max_x-min_x))-1\n",
        "    return x"
      ],
      "execution_count": 625,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6NFycRWNtEI"
      },
      "source": [
        "# funcao retorna os dados a forma original - xi ISOLADO DA FUNCAO: NORMATIZA(X)\n",
        "def Original(x,x_old):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x_old[i].max()\n",
        "        min_x=x_old[i].min()\n",
        "        x[i]=((x[i]+1)/2)*(max_x-min_x)+min_x\n",
        "    return x"
      ],
      "execution_count": 626,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRm1LcrNuMk"
      },
      "source": [
        "DAT_OLD=[] #Criar um dataframe em branco\n",
        "DAT_OLD=df.copy() #No dataframe em branco esta colocando os dados de df (dataframe que chamou no inicio)\n",
        "DAT=Normatiza(df) #No dataframe DAT coloca o dataframe df normatizado"
      ],
      "execution_count": 627,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "iWlBoKYCCTZD",
        "outputId": "70833626-3fc8-4c54-d34c-6360be72b852"
      },
      "source": [
        "DAT #mostra o dataframe DAT que Ã© o df normatizado"
      ],
      "execution_count": 628,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.117028</td>\n",
              "      <td>0.285241</td>\n",
              "      <td>0.215087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.180186</td>\n",
              "      <td>0.253589</td>\n",
              "      <td>-0.017329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.334985</td>\n",
              "      <td>0.102687</td>\n",
              "      <td>0.710499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.297833</td>\n",
              "      <td>-0.019875</td>\n",
              "      <td>0.014611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.540605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.983901</td>\n",
              "      <td>-0.186603</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.702786</td>\n",
              "      <td>-0.169672</td>\n",
              "      <td>-0.033639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.571517</td>\n",
              "      <td>-0.258373</td>\n",
              "      <td>-0.524295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.161610</td>\n",
              "      <td>-0.479205</td>\n",
              "      <td>0.854570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.409288</td>\n",
              "      <td>-0.709974</td>\n",
              "      <td>0.474686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>-0.784321</td>\n",
              "      <td>0.700306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.330031</td>\n",
              "      <td>-0.828487</td>\n",
              "      <td>0.094122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.952941</td>\n",
              "      <td>-0.750460</td>\n",
              "      <td>0.462453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.760991</td>\n",
              "      <td>-0.935223</td>\n",
              "      <td>-0.148488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.609907</td>\n",
              "      <td>-0.974236</td>\n",
              "      <td>0.027523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.631579</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.378865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.667492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.056065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.463777</td>\n",
              "      <td>-0.960250</td>\n",
              "      <td>-0.113150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.313581</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.864396</td>\n",
              "      <td>-0.753404</td>\n",
              "      <td>0.270812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.665015</td>\n",
              "      <td>-0.358484</td>\n",
              "      <td>-0.435270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.388854</td>\n",
              "      <td>-0.807140</td>\n",
              "      <td>-0.872919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.382043</td>\n",
              "      <td>-0.542142</td>\n",
              "      <td>0.096840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.583901</td>\n",
              "      <td>-0.705558</td>\n",
              "      <td>-0.059463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.562229</td>\n",
              "      <td>-0.671329</td>\n",
              "      <td>0.020048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.667648</td>\n",
              "      <td>0.049269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.535604</td>\n",
              "      <td>-0.673169</td>\n",
              "      <td>0.423038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.699301</td>\n",
              "      <td>0.507985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.525697</td>\n",
              "      <td>-0.642989</td>\n",
              "      <td>-0.232756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Di            Do         L  Teta        RL        Eu      Etta\n",
              "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.117028  0.285241  0.215087\n",
              "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6  0.180186  0.253589 -0.017329\n",
              "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6  0.334985  0.102687  0.710499\n",
              "3  -6.250000e-01 -6.250000e-01  0.621622   0.6  0.297833 -0.019875  0.014611\n",
              "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6 -1.000000 -0.007729 -0.540605\n",
              "5  -6.250000e-01  6.250000e-01 -0.549550   0.6 -0.983901 -0.186603 -1.000000\n",
              "6  -6.250000e-01  6.250000e-01  0.621622  -0.6 -0.702786 -0.169672 -0.033639\n",
              "7  -6.250000e-01  6.250000e-01  0.621622   0.6 -0.571517 -0.258373 -0.524295\n",
              "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.161610 -0.479205  0.854570\n",
              "9   6.250000e-01 -6.250000e-01 -0.549550   0.6  0.409288 -0.709974  0.474686\n",
              "10  6.250000e-01 -6.250000e-01  0.621622  -0.6  0.389474 -0.784321  0.700306\n",
              "11  6.250000e-01 -6.250000e-01  0.621622   0.6  0.330031 -0.828487  0.094122\n",
              "12  6.250000e-01  6.250000e-01 -0.549550  -0.6 -0.952941 -0.750460  0.462453\n",
              "13  6.250000e-01  6.250000e-01 -0.549550   0.6 -0.760991 -0.935223 -0.148488\n",
              "14  6.250000e-01  6.250000e-01  0.621622  -0.6 -0.609907 -0.974236  0.027523\n",
              "15  6.250000e-01  6.250000e-01  0.621622   0.6 -0.631579 -1.000000 -0.378865\n",
              "16 -1.000000e+00 -2.220446e-16  0.027027   0.0 -0.667492  1.000000  0.056065\n",
              "17  1.000000e+00 -2.220446e-16  0.027027   0.0 -0.463777 -0.960250 -0.113150\n",
              "18  2.220446e-16 -1.000000e+00  0.027027   0.0  1.000000 -0.313581  1.000000\n",
              "19  2.220446e-16  1.000000e+00  0.027027   0.0 -0.864396 -0.753404  0.270812\n",
              "20  2.220446e-16 -2.220446e-16 -1.000000   0.0 -0.665015 -0.358484 -0.435270\n",
              "21  2.220446e-16 -2.220446e-16  1.000000   0.0 -0.388854 -0.807140 -0.872919\n",
              "22  2.220446e-16 -2.220446e-16  0.027027  -1.0 -0.382043 -0.542142  0.096840\n",
              "23  2.220446e-16 -2.220446e-16  0.027027   1.0 -0.583901 -0.705558 -0.059463\n",
              "24  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.562229 -0.671329  0.020048\n",
              "25  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.667648  0.049269\n",
              "26  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.535604 -0.673169  0.423038\n",
              "27  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.699301  0.507985\n",
              "28  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.525697 -0.642989 -0.232756"
            ]
          },
          "metadata": {},
          "execution_count": 628
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHAmeF3u9b1v"
      },
      "source": [
        "#dividindo randomicamente os dados de DAT em treino e teste\n",
        "train=DAT.sample(frac=0.8,random_state=None)\n",
        "test=DAT.drop(train.index)"
      ],
      "execution_count": 629,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3NrCwW9mUU"
      },
      "source": [
        "#Definindo as variaveis independentes\n",
        "x_train=train.iloc[:,[0,1,2,3]]\n",
        "x_test=test.iloc[:,[0,1,2,3]]\n",
        "X_OLD=DAT_OLD.iloc[:,[0,1,2,3]]"
      ],
      "execution_count": 630,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHep1do94DF",
        "outputId": "53b69687-2bbf-4859-e61a-4c0931eba312"
      },
      "source": [
        "#variaveis independentes de treino e teste\n",
        "print(x_train)\n",
        "print (x_test)"
      ],
      "execution_count": 631,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Di            Do         L  Teta\n",
            "15  6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "11  6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "13  6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "10  6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "7  -6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "20  2.220446e-16 -2.220446e-16 -1.000000   0.0\n",
            "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "22  2.220446e-16 -2.220446e-16  0.027027  -1.0\n",
            "23  2.220446e-16 -2.220446e-16  0.027027   1.0\n",
            "19  2.220446e-16  1.000000e+00  0.027027   0.0\n",
            "26  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "18  2.220446e-16 -1.000000e+00  0.027027   0.0\n",
            "28  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "6  -6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "25  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "17  1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "9   6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "24  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "16 -1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "              Di            Do         L  Teta\n",
            "3  -6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "5  -6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "12  6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "14  6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "21  2.220446e-16 -2.220446e-16  1.000000   0.0\n",
            "27  2.220446e-16 -2.220446e-16  0.027027   0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4vJ0_69yiE",
        "outputId": "96277411-e1eb-4908-bb32-1a0d39c3cf35"
      },
      "source": [
        "#definindo a variavel dependente RL\n",
        "y_train=train.iloc[:,[4]]\n",
        "y_test=test.iloc[:,[4]]\n",
        "Y_OLD=DAT_OLD.iloc[:,[4]]\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": 632,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          RL\n",
            "15 -0.631579\n",
            "2   0.334985\n",
            "11  0.330031\n",
            "1   0.180186\n",
            "13 -0.760991\n",
            "10  0.389474\n",
            "7  -0.571517\n",
            "20 -0.665015\n",
            "8   0.161610\n",
            "22 -0.382043\n",
            "23 -0.583901\n",
            "19 -0.864396\n",
            "26 -0.535604\n",
            "18  1.000000\n",
            "28 -0.525697\n",
            "6  -0.702786\n",
            "25 -0.550464\n",
            "17 -0.463777\n",
            "9   0.409288\n",
            "4  -1.000000\n",
            "0   0.117028\n",
            "24 -0.562229\n",
            "16 -0.667492\n",
            "          RL\n",
            "3   0.297833\n",
            "5  -0.983901\n",
            "12 -0.952941\n",
            "14 -0.609907\n",
            "21 -0.388854\n",
            "27 -0.550464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4haSAcEPN2S7"
      },
      "source": [
        "#define a rede neural\n",
        "#nessa rede vao ser usados 3 camadas: Input + hidden + output\n",
        "#o numero de neuronios da output eh 1, porque tem 1 resposta (FIE)\n",
        "#o numero de neuronios na hidden eh arbitrario. O artigo fez 12 neuronios nessa camada\n",
        "#funcao de ativicao eh a logistic, segundo o artigo\n",
        "model = MLPRegressor(random_state=1,solver='lbfgs',activation='tanh', learning_rate = 'adaptive', alpha=1e-5, \n",
        "                     hidden_layer_sizes= tuple(100 for _ in range(3)))"
      ],
      "execution_count": 633,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhi90gVN3YV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63324b98-d6e2-402c-97e3-e378afc183ce"
      },
      "source": [
        "#treina a rede neural\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 634,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "             hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive',\n",
              "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "             power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
              "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 634
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-yOW0ZmN4e0"
      },
      "source": [
        "#usa a rede neural para treino e teste\n",
        "y_calc_train=model.predict(x_train)\n",
        "y_calc_test=model.predict(x_test)"
      ],
      "execution_count": 635,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfwjcMtN58a"
      },
      "source": [
        "#transforma a saida da rede em dataframe \n",
        "y_calc_train=pd.DataFrame(y_calc_train)\n",
        "y_calc_test=pd.DataFrame(y_calc_test)\n",
        "col_names=list(y_train)\n",
        "y_calc_train.columns = col_names\n",
        "y_calc_test.columns = col_names"
      ],
      "execution_count": 636,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RboALKIN7as"
      },
      "source": [
        "#Desnormatizar os dados obtidos da rede neural\n",
        "y_calc_train=Original(y_calc_train,Y_OLD)\n",
        "y_calc_test=Original(y_calc_test,Y_OLD)"
      ],
      "execution_count": 637,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjoCPU8bN92O"
      },
      "source": [
        "#recupera os dados originais \n",
        "test=[]\n",
        "train=[]\n",
        "train=Original(y_train,Y_OLD)\n",
        "test=Original(y_test,Y_OLD)"
      ],
      "execution_count": 638,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiL9upNxN_RT"
      },
      "source": [
        "#Resposta para fazer o grafico (FIE-treino)\n",
        "resist_obs_train=[]\n",
        "resist_calc_train=[]\n",
        "resist_calc_train=y_calc_train['RL'].copy()\n",
        "resist_obs_train=train['RL'].copy()"
      ],
      "execution_count": 639,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_g9O8DOAfQ"
      },
      "source": [
        "#Resposta para fazer o grafico (FIE-teste)\n",
        "resist_obs_test=[]\n",
        "resist_calc_test=[]\n",
        "resist_calc_test=y_calc_test['RL'].copy()\n",
        "resist_obs_test=test['RL'].copy()"
      ],
      "execution_count": 640,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHCXQdoOBtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2bea4a0f-762b-4e44-a6cc-7611e574fe9d"
      },
      "source": [
        "#expressa os dois dados em figura - EULER\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.scatter(resist_obs_test,resist_calc_test, s=10, c='b', marker=\"s\", label='teste')\n",
        "ax1.scatter(resist_obs_train,resist_calc_train, s=10, c='r', marker=\"o\", label='treino')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylabel('FIE Calc')\n",
        "plt.xlabel('FIE Obs')\n",
        "plt.show()"
      ],
      "execution_count": 641,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAasElEQVR4nO3dfZAV9Z3v8fdHRHDCgIoTCp0ksGoeCEkwGYkuoeJDeIh4R02pWWL2eu9GYasklWx5EU0lMd7oLay7ieYmxAJXASteIouuTozZjKWom9SNOigxBLZEF0whRkZW5GHiqPi9f3QPHA4zh3nq8zD9eVWdOt19+kx/p6v4zI9f//rXigjMzCw/jqp0AWZmVl4OfjOznHHwm5nljIPfzCxnHPxmZjlzdKUL6I0TTzwxJkyYUOkyzMxqyrp1616PiIbi7TUR/BMmTKCtra3SZZiZ1RRJL3e33V09ZmY54+A3M8sZB7+ZWc7URB9/d9555x22bdvGW2+9VelSKmLkyJE0NjYyfPjwSpdiZjWmZoN/27Zt1NfXM2HCBCRVupyyigh27tzJtm3bmDhxYqXLMbMaU7NdPW+99RZjx47NXegDSGLs2LG5/d+OmQ1MzQY/kMvQ75Ln390sN1paYMGC5H0Q1XTwm5kNWS0tMHcuLFmSvA9i+Dv4+2nXrl389Kc/7dd3b7vtNjo6Oga5IjMbUlpboSsnOjqS9UHi4O8nB7+ZZWrmTKirS5br6pL1QVKzo3oq7brrruOll15iypQpzJgxg/e///2sXr2azs5OLr74Ym688Ub27dvHZZddxrZt29i/fz/f+c53eO2119i+fTvnnHMOJ554ImvXrqW1tZUbbriBzs5OTjnlFJYvX86oUaMq/SuaWSU1N8OqVUlLf+bMZH2wRETVvz7zmc9EsY0bNx62rZT6+gg4+Kqv79PXD7Nly5b4+Mc/HhERv/71r+Oqq66K9957L/bv3x9z5syJJ554ItasWRNXXnnlge/s2rUrIiI+9KEPRXt7e0REtLe3x/Tp02Pv3r0REbF48eK48cYbe1VDX8+BmeUL0BbdZGpuWvx79pReH4jW1lZaW1s5/fTTAdi7dy+bN29m+vTpXHPNNSxatIgLLriA6dOnH/bd3/3ud2zcuJFp06YB8Pbbb3PWWWcNXnFmZkVyE/xZigiuv/565s+ff9hnzz77LA8//DDf/va3Oe+88/jud7972HdnzJjBqlWrylWumeWcL+72U319PXvS/zbMmjWLu+66i7179wLwyiuvsGPHDrZv305dXR1f/epXWbhwIc8+++xh3z3zzDP57W9/y4svvgjAvn37eOGFFyrwG5lZXuSmxV9ff2j3Tn39wH7e2LFjmTZtGpMnT+aLX/wiX/nKVw500YwaNYqf/exnvPjiiyxcuJCjjjqK4cOHc/vttwMwb948Zs+ezUknncTatWtZsWIFc+fOpbOzE4CbbrqJD3/4wwMr0MysB0r6/6tbU1NTFD+IZdOmTXzsYx+rUEXVwefAzEqRtC4imoq3u6vHzCxnHPxmZjnj4DczyxkHv5lZzmQe/JKGSXpO0kPp+kRJT0l6UdK9ko7JugYzMzuoHC3+bwCbCtZvAW6NiFOBN4CvlaEGMzNLZRr8khqBOcA/pesCzgXWpLusBC7Ksoas9Gd2zu3bt3PJJZdkVJGZWe9k3eK/DbgWeC9dHwvsioh30/VtwMndfVHSPEltktra29szLrPvegr+d999t5u9EyeddBJr1qzp8XMzs3LILPglXQDsiIh1/fl+RCyLiKaIaGpoaBjk6gaucFrmM844g+nTp9Pc3MykSZPYv38/Cxcu5IwzzuCTn/wkS5cuBWDr1q1MnjwZgBUrVvClL32J2bNnc9ppp3Httdce+NmrVq3iE5/4BJMnT2bRokUV+f3MbOjKcsqGaUCzpPOBkcBo4EfAcZKOTlv9jcArGdZwqJaWQZvbevHixWzYsIH169fz+OOPM2fOHDZs2MDEiRNZtmwZY8aM4ZlnnqGzs5Np06Yxc+bMw56Tu379ep577jlGjBjBRz7yEb7+9a8zbNgwFi1axLp16zj++OOZOXMmDzzwABddVJM9YmZWhTJr8UfE9RHRGBETgL8BHouIy4G1QFdH9xXAg1nVcIgMn18JMHXqVCZOnAgk0zTffffdTJkyhc9+9rPs3LmTzZs3H/ad8847jzFjxjBy5EgmTZrEyy+/zDPPPMPZZ59NQ0MDRx99NJdffjlPPvnkoNZqZvlWiUnaFgE/l3QT8BxwZ1mO2t3zKwfxiTbve9/7DixHBD/+8Y+ZNWvWIfts3br1kPURI0YcWB42bFjJ6wNmZoOlLDdwRcTjEXFBuvwfETE1Ik6NiEsjorMcNQz28ysLp1YuNmvWLG6//XbeeecdAF544QX27dvXq587depUnnjiCV5//XX279/PqlWr+PznPz+gWs3MCuVmWubBfn5l4bTMxx57LOPGjTvw2ZVXXsnWrVv59Kc/TUTQ0NDAAw880KufO378eBYvXsw555xDRDBnzhwuvPDCAdVqZlbI0zLXMJ8DMyvF0zKbmRng4Dczy52aDv5a6KbKSp5/dzMbmJoN/pEjR7Jz585cBmBEsHPnTkaOHFnpUsysBtXsqJ7Gxka2bdtGNc7jUw4jR46ksbGx0mWYWQ2q2eAfPnz4gTtlzcys92q2q8fMzPrHwW9mljMOfjOznHHwm5nljIPfzCxnHPxmZjnj4DczyxkHv5lZzjj4zcxyxsFvZpYzDn4zs5xx8JuZ5YyD38wsZzILfkkjJT0t6feS/ijpxnT7CklbJK1PX1OyqsHMzA6X5bTMncC5EbFX0nDgN5J+lX62MCLWZHhsMzPrQWbBH8mjsfamq8PTV/4el2VmVmUy7eOXNEzSemAH8EhEPJV+dLOk5yXdKmlED9+dJ6lNUlten7JlZpaFTIM/IvZHxBSgEZgqaTJwPfBR4AzgBGBRD99dFhFNEdHU0NCQZZlmZrlSllE9EbELWAvMjohXI9EJLAemlqMGMzNLZDmqp0HScenyscAM4N8ljU+3CbgI2JBVDWZmdrgsR/WMB1ZKGkbyB2Z1RDwk6TFJDYCA9cDfZ1iDmZkVyXJUz/PA6d1sPzerY5qZ2ZH5zl0zs5xx8JuZ5YyD38wsZxz8ZmY54+A3s75raYEFC5J3qzkOfjPrm5YWmDsXlixJ3h3+NSfLcfxmNpS0tEBrK2zZAh0dybaOjmRbc3Nla7M+cfCb2ZF1tfI7OuCYY2DECOjshLo6mDmz0tVZHzn4zezIWlsPtvLffhvOPx8mTkxC3639muPgN7MjmzkTli9Pwr+uDubPd+DXMAe/mR1ZczOsWpW0/N3Kr3kOfjM7eOG2VKg3NzvwhwgP5zTLkdGjQTr4Gj2aJPQvvTQZnnnppR6emQMOfrMc2bOnm/WlS5MLtpC8L11a9rqsvBz8ZmY54+A3y7v585Nx+ZC8z59f2Xosc764a5Yj9fWHdvfU15NcsF292iN2csTBb5Yju3f38IFH7OSKu3rMzHLGwW9mljMOfjOznMks+CWNlPS0pN9L+qOkG9PtEyU9JelFSfdKOiarGszM7HBZtvg7gXMj4lPAFGC2pDOBW4BbI+JU4A3gaxnWYGZmRTIL/kjsTVeHp68AzgXWpNtXAhdlVYOZmR0u0z5+ScMkrQd2AI8ALwG7IuLddJdtwMk9fHeepDZJbe3t7VmWaWaWK5kGf0Tsj4gpQCMwFfhoH767LCKaIqKpoaEhsxrNzPKmLKN6ImIXsBY4CzhOUteNY43AK+WowazmtbTAggWePdMGLMtRPQ2SjkuXjwVmAJtI/gBcku52BfBgVjWYDRldz7xdsiR5d/jbAGQ5ZcN4YKWkYSR/YFZHxEOSNgI/l3QT8BxwZ4Y1mNW2rgekbNly8Jm3HR3JNk+xYP2UWfBHxPPA6d1s/w+S/n4zK6Wrld/RkcyaecwxyXz5dXXJZGpm/XTErh5J/6uryyZdPz5trZtZllpbD7byOzvhC1+Aq69Onn3r1r4NQG/6+L+YXpwFICLeAM7PriQzA5JWfV1dslxXl8yT/5OfOPRtwHrT1TNM0oiI6IQDF2pHZFuWmdHcnLTuPU++DbLeBP89wKOSlqfr/53kjlszGwxdF3C7C3fPk28ZOGLwR8Qtkp4Hzks3fT8ifp1tWWY5UXgBd/ly999bWfRqVE9E/Ar4Vca1mOVP4QVcD9O0Munx4q6kPZJ2d/PaI6mnB7iZWV8UX8D1ME0rgx5b/BFRX85CzHLJF3CtAnp9A5ek9wMju9Yj4k+ZVGSWN76Aa2XWmxu4miVtBrYATwBbcX+/mVnN6s0NXN8HzgReiIiJJKN7fpdpVWZmlpneBP87EbETOErSURGxFmjKuC4zM8tIb/r4d0kaBTwJ3CNpB7Av27LMzCwrvWnxXwh0AP8A/CvJ4xP/S5ZFmZlZdkqN4z9V0rSI2BcR70XEuxGxEngWOK6n75mZWXUr1eK/DejuRq0308/MzKwGlQr+cRHxh+KN6bYJmVVkZmaZKhX8pbpzjh3sQszMrDxKBX+bpKuKN0q6EliXXUlmZpalUsM5vwn8i6TLORj0TcAxwMVZF2ZmZtkoNUnba8BfSzoHmJxu/mVEPFaWyszMLBO9eRDLWmBtX3+wpA8AdwPjgACWRcSPJH0PuApoT3f9VkQ83Nefb2Zm/dPr2Tn74V3gmoh4VlI9sE7SI+lnt0bEP2Z4bDMz60FmwR8RrwKvpst7JG0CTs7qeGZm1jul7tz9aMHyiKLPzuzLQSRNAE4Hnko3LZD0vKS7JB3fw3fmSWqT1Nbe3t7dLmZm1g+lhnP+34Ll/1f02U97e4B0grf7gG9GxG7gduAUYArJ/wh+0N33ImJZRDRFRFNDQ0NvD2dmZkdQKvjVw3J3693/AGk4SejfExH3QzJaKCL2R8R7wB3A1D7Ua2ZmA1Qq+KOH5e7WDyNJwJ3Apoj4YcH28QW7XQxs6EWdZmY2SEpd3G2U9H9IWvddy6TrvblIOw34W+APktan274FzJU0heSPx1Zgfn8KNzOz/ikV/AsLltuKPiteP0xE/Ibuu4Q8Zt/MrIJK3bm7spyFmJlZefQY/JJ+QYm+/IhozqQiMzPLVKmuHt9Za2Y2BJUK/i0R8aeyVWJmZmVRajjnA10Lku4rQy1mZlYGvb2B66+yLsRq3+jRIB18jR5d6YrMrDv9vYHL7DB79pReN7PqUKqP/1OSdpO0/I9Nl0nXIyLcnjMzq0GlxvEPK2chZmZWHqW6esz6pL6+9LqZVYcsn8BlObN795H3MbPKc4vfzCxnHPxmZjnj4DczyxkHv5lZzjj4zcxyxsFvZpYzDn4zs5xx8JuZ5YyD38wsZxz8ZmY54+C3wdfSAgsWJO9mVnUyC35JH5C0VtJGSX+U9I10+wmSHpG0OX0/PqsarAJaWmDuXFiyJHl3+JtVnSxb/O8C10TEJOBM4GpJk4DrgEcj4jTg0XTdhorWVujoSJY7OpJ1M6sqmQV/RLwaEc+my3uATcDJwIXAynS3lcBFWdVgFTBzJtTVJct1dcm6mVWVskzLLGkCcDrwFDAuIl5NP/ozMK6H78wD5gF88IMfzL5IGxzNzbBqVdLSnzkzWTezqqKIbB+nK2kU8ARwc0TcL2lXRBxX8PkbEVGyn7+pqSna2toyrdPMbKiRtC4imoq3ZzqqR9Jw4D7gnoi4P938mqTx6efjgR1Z1mBmZofKclSPgDuBTRHxw4KPWoAr0uUrgAezqsHMzA6XZYt/GvC3wLmS1qev84HFwAxJm4EvpOtWzTwu32xIyezibkT8BlAPH5+X1XFtkHWNy+/ogOXLkwu3vmBrVtN8566V5nH5ZkOOg99K87h8syGnLOP4rYZ5XL7ZkOPgtyNrbnbgmw0h7uoxM8sZB7+ZWc44+M3McsZ9/HnR0sLSS1ppf2cMY3iTNxlD07D1zJ4FzJ/vPnyzHHHw50F6E9b8dzoIkrvqAtB+4GHg0Udh9WqHv1lOOPiHqpaWZAjmmDHJcnoTVtet1IfcUt3Zmezr4DfLBQf/UFQ4zUKRQ1r8XRtHjPCNWWY54uAfigqnWSiwQZN5IJrdx2+Wcw7+oWjmzGRCtcLwr6tj8qqbmeyAN8s9B/9QVDjNwpgx8Oabnm7BzA5w8Neyrgu43YW6p1kwsx74Bq5a1XUBd8kSmDuXL9e1IHHgNXp0pQs0s2rl4K9VRfPkf+4vh86Tv2dPBWoys5rg4K8VxY8/LJon/xE8HNPMesd9/LWgpQUuvRTefhvuuAP++Z8Pmyf/Fxe6P9/MesfBXwuWLk1CH5L3pUsPXrxNL+DW1x/avVNfX4E6zawmOPiHiN27K12BmdWKzPr4Jd0laYekDQXbvifpFUnr09f5WR2/ZhX35UNyZ+2IEcnyiBHJuplZP2XZ4l8B/AS4u2j7rRHxjxket3YVzrGzfHnSh9/VnbN6tZ97a2aDIrPgj4gnJU3I6ucPSUVDNA+ZMdM3ZJnZIKnEcM4Fkp5Pu4KO72knSfMktUlqa29vL2d9lVM0RNMzZppZFhQR2f3wpMX/UERMTtfHAa+TzAr8fWB8RPzdkX5OU1NTtLW1ZVZnVSk1DYOZWR9IWhcRTcXbyzqqJyJeKyjoDuChch6/JrhLx8wyVtauHknjC1YvBjb0tK+ZmWUjsxa/pFXA2cCJkrYBNwBnS5pC0tWzFcjfuER35ZhZhWU5qmduN5vvzOp4NaGn4ZpmZmXkSdrKqbvhmmZmZebgLycP1zSzKuC5esqpaEZNd/OYWSXkMvhHjz58JsuyTXLm4ZpmVmG57OopfjqVn1ZlZnmSy+A3M8szB7+ZWc7kMviLn07lp1WZWZ7kMvh374aIg68+Xdjt7kEpZmY1JJfB329dd94uWZK8O/zNrAY5+PvCd96a2RDg4O8L33lrZkNALm/g6jffeWtmQ4CDv698562Z1Th39ZiZ5YyD38wsZxz8ZmY54+A3M8sZB7+ZWc44+M3McsbBb2aWM5kFv6S7JO2QtKFg2wmSHpG0OX0/PqvjA55QzcysG1m2+FcAs4u2XQc8GhGnAY+m69nwhGpmZt3KLPgj4kngP4s2XwisTJdXAhdldfziCdV+fGErEkjJM3fNzPKq3H384yLi1XT5z8C4nnaUNE9Sm6S29vb2vh+pYEK1fdTxCAcnVPMzds0szyp2cTciAogSny+LiKaIaGpoaOj7AbomVLv6auayil/g+XXMzKD8k7S9Jml8RLwqaTywI9OjpROq/WJJpkcxM6sp5W7xtwBXpMtXAA+W46B+xq6Z2UGZtfglrQLOBk6UtA24AVgMrJb0NeBl4LKsjl+oT8/UNTMb4jIL/oiY28NH52V1TDMzOzLfuWtmljMOfjOznHHwm5nljIPfzCxnHPxmZjmj5Aba6iapnWT4Z1+cCLyeQTnl4Norw7VXRi3XDtVd/4ci4rCpD2oi+PtDUltENFW6jv5w7ZXh2iujlmuH2qzfXT1mZjnj4Dczy5mhHPzLKl3AALj2ynDtlVHLtUMN1j9k+/jNzKx7Q7nFb2Zm3XDwm5nlzJAIfkl3SdohaUPBthMkPSJpc/p+fCVr7EkPtX9P0iuS1qev8ytZY08kfUDSWkkbJf1R0jfS7VV/7kvUXvXnXtJISU9L+n1a+43p9omSnpL0oqR7JR1T6VqLlah9haQtBed9SqVr7YmkYZKek/RQul71573YkAh+YAUwu2jbdcCjEXEa8Gi6Xo1WcHjtALdGxJT09XCZa+qtd4FrImIScCZwtaRJ1Ma576l2qP5z3wmcGxGfAqYAsyWdCdxCUvupwBvA1ypYY096qh1gYcF5X1+5Eo/oG8CmgvVaOO+HGBLBHxFPAv9ZtPlCYGW6vBK4qKxF9VIPtdeEiHg1Ip5Nl/eQ/GM4mRo49yVqr3qR2JuuDk9fAZwLrEm3V+t576n2miCpEZgD/FO6LmrgvBcbEsHfg3ER8Wq6/GdgXCWL6YcFkp5Pu4KqrqukmKQJwOnAU9TYuS+qHWrg3KfdDetJnlv9CPASsCsi3k132UaV/iErrj0ius77zel5v1XSiAqWWMptwLXAe+n6WGrkvBcaysF/QCRjVmumVQHcDpxC8l/hV4EfVLac0iSNAu4DvhkRhzzostrPfTe118S5j4j9ETEFaASmAh+tcEm9Vly7pMnA9SS/wxnACcCiCpbYLUkXADsiYl2laxmooRz8r0kaD5C+76hwPb0WEa+l/zjeA+4g+YddlSQNJwnOeyLi/nRzTZz77mqvpXMPEBG7gLXAWcBxkroep9oIvFKxwnqhoPbZaddbREQnsJzqPO/TgGZJW4Gfk3Tx/IgaO+8wtIO/BbgiXb4CeLCCtfRJV2imLgY29LRvJaX9m3cCmyLihwUfVf2576n2Wjj3khokHZcuHwvMILlGsRa4JN2tWs97d7X/e0FDQSR95FV33iPi+ohojIgJwN8Aj0XE5dTAeS82JO7clbQKOJtketTXgBuAB4DVwAdJpnS+LCKq7iJqD7WfTdLVEMBWYH5Bn3nVkPQ54N+AP3Cwz/NbJH3lVX3uS9Q+lyo/95I+SXIRcRhJ4211RPxPSX9F0hI9AXgO+Gragq4aJWp/DGgABKwH/r7gInDVkXQ28D8i4oJaOO/FhkTwm5lZ7w3lrh4zM+uGg9/MLGcc/GZmOePgNzPLGQe/mVnOOPgttyTtL5gNcr2kCZLOLph18b9Jai/aZ1I3P6dR0oPpbKQvSfpR1wyN6c/4Sbl/N7NSHPyWZ38pmA1ySkRs7Wafe4v22Vj4YXrD0f3AA+lspB8GRgE3Z169WT85+M0G5lzgrYhYDsk8NMA/AH8nqS7d5wOSHk//R3ADgKT3SfplOi/9Bklfrkz5lkdHH3kXsyHr2HSWSIAtEXFxN/t8Ob3Lt8tZEfGXgvWPA4dM2hURuyX9CTg13TQVmAx0AM9I+iXwIWB7RMwBkDRm4L+OWe84+C3P/pLOElnKvRGxYIDHeSQidgJIuh/4HPAw8ANJtwAPRcS/DfAYZr3mrh6zgdkIfKZwg6TRJPMUvZhuKp4XJSLiBeDTJHMF3STpu1kXatbFwW82MI8CdZL+KyQPGSGZw39FRHSk+8xQ8hziY0lmnvytpJOAjoj4GfC/Sf4ImJWFg9+stC8XDef868IP0wfNXAxcKmkz8ALwFslMn12eJpn3/3ngvohoAz4BPJ1eY7gBuKkMv4sZ4Nk5zcxyxy1+M7OccfCbmeWMg9/MLGcc/GZmOePgNzPLGQe/mVnOOPjNzHLm/wMOyYmi+WNXcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxqGLrm6OCHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285f8984-d2ba-477d-8330-6b00e0922289"
      },
      "source": [
        "#checar a qualidade da regressao PARA TESTE\n",
        "mse=mean_squared_error(resist_obs_test,resist_calc_test)\n",
        "print(\"MSE teste=\",mse)\n",
        "R2=r2_score(resist_obs_test,resist_calc_test)\n",
        "print(\"R^2 teste=\",R2)"
      ],
      "execution_count": 642,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE teste= 2.3290770701488013\n",
            "R^2 teste= 0.9511558823859724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEznkoupODnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec7e13f-a85a-4893-b3f5-9c58104d926b"
      },
      "source": [
        "#checar a qualidade da regressao PARA TREINO\n",
        "mse=mean_squared_error(resist_obs_train,resist_calc_train)\n",
        "print(\"MSE treino=\",mse)\n",
        "R2=r2_score(resist_obs_train,resist_calc_train)\n",
        "print(\"R^2 treino=\",R2)"
      ],
      "execution_count": 643,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE treino= 0.013471354464613134\n",
            "R^2 treino= 0.9998042303379064\n"
          ]
        }
      ]
    }
  ]
}