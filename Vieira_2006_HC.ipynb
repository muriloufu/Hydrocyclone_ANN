{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vieira_2006_HC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNDUcqHKLrVU1w3s2nutf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muriloufu/Hydrocyclone_ANN/blob/main/Vieira_2006_HC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOID4YHpNewq"
      },
      "source": [
        "#bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_qSQRQxNkT4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "15ccc5da-fff6-400c-9696-bbe59a116a5d"
      },
      "source": [
        "#selecao do dataset\n",
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-19761ae6-7082-4d1f-a8a1-935a599c56e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-19761ae6-7082-4d1f-a8a1-935a599c56e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tese_LG_2006_01.xlsx to Tese_LG_2006_01 (7).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHeAwtRNnC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "0cac8f15-d6a9-40ff-9569-80acedc4ca54"
      },
      "source": [
        "#colocar todo o dataset em um dataframe\n",
        "df=pd.read_excel(io.BytesIO(uploaded['Tese_LG_2006_01.xlsx']))\n",
        "df"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>28.28</td>\n",
              "      <td>4493</td>\n",
              "      <td>65.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.30</td>\n",
              "      <td>4407</td>\n",
              "      <td>61.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>31.80</td>\n",
              "      <td>3997</td>\n",
              "      <td>72.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.20</td>\n",
              "      <td>3664</td>\n",
              "      <td>62.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>3697</td>\n",
              "      <td>54.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>10.50</td>\n",
              "      <td>3211</td>\n",
              "      <td>47.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>15.04</td>\n",
              "      <td>3257</td>\n",
              "      <td>61.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>17.16</td>\n",
              "      <td>3016</td>\n",
              "      <td>54.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>29.00</td>\n",
              "      <td>2416</td>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1789</td>\n",
              "      <td>69.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>32.68</td>\n",
              "      <td>1587</td>\n",
              "      <td>72.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.72</td>\n",
              "      <td>1467</td>\n",
              "      <td>63.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1679</td>\n",
              "      <td>68.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>14.10</td>\n",
              "      <td>1177</td>\n",
              "      <td>59.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>16.54</td>\n",
              "      <td>1071</td>\n",
              "      <td>62.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>16.19</td>\n",
              "      <td>1001</td>\n",
              "      <td>56.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.61</td>\n",
              "      <td>6435</td>\n",
              "      <td>62.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.7</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1109</td>\n",
              "      <td>60.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>42.54</td>\n",
              "      <td>2866</td>\n",
              "      <td>76.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.3</td>\n",
              "      <td>10.5</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>12.43</td>\n",
              "      <td>1671</td>\n",
              "      <td>66.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>117</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.65</td>\n",
              "      <td>2744</td>\n",
              "      <td>55.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>228</td>\n",
              "      <td>14.5</td>\n",
              "      <td>20.11</td>\n",
              "      <td>1525</td>\n",
              "      <td>49.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.22</td>\n",
              "      <td>2245</td>\n",
              "      <td>63.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.96</td>\n",
              "      <td>1801</td>\n",
              "      <td>61.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.31</td>\n",
              "      <td>1894</td>\n",
              "      <td>62.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1904</td>\n",
              "      <td>62.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.74</td>\n",
              "      <td>1889</td>\n",
              "      <td>68.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1818</td>\n",
              "      <td>69.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.90</td>\n",
              "      <td>1971</td>\n",
              "      <td>58.59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Di    Do    L  Teta     RL    Eu   Etta\n",
              "0   4.8   6.6  142  11.2  28.28  4493  65.18\n",
              "1   4.8   6.6  142  17.8  29.30  4407  61.76\n",
              "2   4.8   6.6  207  11.2  31.80  3997  72.47\n",
              "3   4.8   6.6  207  17.8  31.20  3664  62.23\n",
              "4   4.8   9.6  142  11.2  10.24  3697  54.06\n",
              "5   4.8   9.6  142  17.8  10.50  3211  47.30\n",
              "6   4.8   9.6  207  11.2  15.04  3257  61.52\n",
              "7   4.8   9.6  207  17.8  17.16  3016  54.30\n",
              "8   7.8   6.6  142  11.2  29.00  2416  74.59\n",
              "9   7.8   6.6  142  17.8  33.00  1789  69.00\n",
              "10  7.8   6.6  207  11.2  32.68  1587  72.32\n",
              "11  7.8   6.6  207  17.8  31.72  1467  63.40\n",
              "12  7.8   9.6  142  11.2  11.00  1679  68.82\n",
              "13  7.8   9.6  142  17.8  14.10  1177  59.83\n",
              "14  7.8   9.6  207  11.2  16.54  1071  62.42\n",
              "15  7.8   9.6  207  17.8  16.19  1001  56.44\n",
              "16  3.9   8.1  174  14.5  15.61  6435  62.84\n",
              "17  8.7   8.1  174  14.5  18.90  1109  60.35\n",
              "18  6.3   5.7  174  14.5  42.54  2866  76.73\n",
              "19  6.3  10.5  174  14.5  12.43  1671  66.00\n",
              "20  6.3   8.1  117  14.5  15.65  2744  55.61\n",
              "21  6.3   8.1  228  14.5  20.11  1525  49.17\n",
              "22  6.3   8.1  174   9.0  20.22  2245  63.44\n",
              "23  6.3   8.1  174  20.0  16.96  1801  61.14\n",
              "24  6.3   8.1  174  14.5  17.31  1894  62.31\n",
              "25  6.3   8.1  174  14.5  17.50  1904  62.74\n",
              "26  6.3   8.1  174  14.5  17.74  1889  68.24\n",
              "27  6.3   8.1  174  14.5  17.50  1818  69.49\n",
              "28  6.3   8.1  174  14.5  17.90  1971  58.59"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_18br6NreR"
      },
      "source": [
        "# funcao normatiza dados\n",
        "def Normatiza(x):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x[i].max()\n",
        "        min_x=x[i].min()\n",
        "        x[i]=2*((x[i]-min_x)/(max_x-min_x))-1\n",
        "    return x"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6NFycRWNtEI"
      },
      "source": [
        "# funcao retorna os dados a forma original - xi ISOLADO DA FUNCAO: NORMATIZA(X)\n",
        "def Original(x,x_old):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x_old[i].max()\n",
        "        min_x=x_old[i].min()\n",
        "        x[i]=((x[i]+1)/2)*(max_x-min_x)+min_x\n",
        "    return x"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRm1LcrNuMk"
      },
      "source": [
        "DAT_OLD=[] #Criar um dataframe em branco\n",
        "DAT_OLD=df.copy() #No dataframe em branco esta colocando os dados de df (dataframe que chamou no inicio)\n",
        "DAT=Normatiza(df) #No dataframe DAT coloca o dataframe df normatizado"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "iWlBoKYCCTZD",
        "outputId": "c9d6dd87-a323-4c98-9d32-d456f173d6e7"
      },
      "source": [
        "DAT #mostra o dataframe DAT que Ã© o df normatizado"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.117028</td>\n",
              "      <td>0.285241</td>\n",
              "      <td>0.215087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.180186</td>\n",
              "      <td>0.253589</td>\n",
              "      <td>-0.017329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.334985</td>\n",
              "      <td>0.102687</td>\n",
              "      <td>0.710499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.297833</td>\n",
              "      <td>-0.019875</td>\n",
              "      <td>0.014611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.540605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.983901</td>\n",
              "      <td>-0.186603</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.702786</td>\n",
              "      <td>-0.169672</td>\n",
              "      <td>-0.033639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.571517</td>\n",
              "      <td>-0.258373</td>\n",
              "      <td>-0.524295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.161610</td>\n",
              "      <td>-0.479205</td>\n",
              "      <td>0.854570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.409288</td>\n",
              "      <td>-0.709974</td>\n",
              "      <td>0.474686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>-0.784321</td>\n",
              "      <td>0.700306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.330031</td>\n",
              "      <td>-0.828487</td>\n",
              "      <td>0.094122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.952941</td>\n",
              "      <td>-0.750460</td>\n",
              "      <td>0.462453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.760991</td>\n",
              "      <td>-0.935223</td>\n",
              "      <td>-0.148488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.609907</td>\n",
              "      <td>-0.974236</td>\n",
              "      <td>0.027523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.631579</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.378865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.667492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.056065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.463777</td>\n",
              "      <td>-0.960250</td>\n",
              "      <td>-0.113150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.313581</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.864396</td>\n",
              "      <td>-0.753404</td>\n",
              "      <td>0.270812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.665015</td>\n",
              "      <td>-0.358484</td>\n",
              "      <td>-0.435270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.388854</td>\n",
              "      <td>-0.807140</td>\n",
              "      <td>-0.872919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.382043</td>\n",
              "      <td>-0.542142</td>\n",
              "      <td>0.096840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.583901</td>\n",
              "      <td>-0.705558</td>\n",
              "      <td>-0.059463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.562229</td>\n",
              "      <td>-0.671329</td>\n",
              "      <td>0.020048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.667648</td>\n",
              "      <td>0.049269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.535604</td>\n",
              "      <td>-0.673169</td>\n",
              "      <td>0.423038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.699301</td>\n",
              "      <td>0.507985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.525697</td>\n",
              "      <td>-0.642989</td>\n",
              "      <td>-0.232756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Di            Do         L  Teta        RL        Eu      Etta\n",
              "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.117028  0.285241  0.215087\n",
              "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6  0.180186  0.253589 -0.017329\n",
              "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6  0.334985  0.102687  0.710499\n",
              "3  -6.250000e-01 -6.250000e-01  0.621622   0.6  0.297833 -0.019875  0.014611\n",
              "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6 -1.000000 -0.007729 -0.540605\n",
              "5  -6.250000e-01  6.250000e-01 -0.549550   0.6 -0.983901 -0.186603 -1.000000\n",
              "6  -6.250000e-01  6.250000e-01  0.621622  -0.6 -0.702786 -0.169672 -0.033639\n",
              "7  -6.250000e-01  6.250000e-01  0.621622   0.6 -0.571517 -0.258373 -0.524295\n",
              "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.161610 -0.479205  0.854570\n",
              "9   6.250000e-01 -6.250000e-01 -0.549550   0.6  0.409288 -0.709974  0.474686\n",
              "10  6.250000e-01 -6.250000e-01  0.621622  -0.6  0.389474 -0.784321  0.700306\n",
              "11  6.250000e-01 -6.250000e-01  0.621622   0.6  0.330031 -0.828487  0.094122\n",
              "12  6.250000e-01  6.250000e-01 -0.549550  -0.6 -0.952941 -0.750460  0.462453\n",
              "13  6.250000e-01  6.250000e-01 -0.549550   0.6 -0.760991 -0.935223 -0.148488\n",
              "14  6.250000e-01  6.250000e-01  0.621622  -0.6 -0.609907 -0.974236  0.027523\n",
              "15  6.250000e-01  6.250000e-01  0.621622   0.6 -0.631579 -1.000000 -0.378865\n",
              "16 -1.000000e+00 -2.220446e-16  0.027027   0.0 -0.667492  1.000000  0.056065\n",
              "17  1.000000e+00 -2.220446e-16  0.027027   0.0 -0.463777 -0.960250 -0.113150\n",
              "18  2.220446e-16 -1.000000e+00  0.027027   0.0  1.000000 -0.313581  1.000000\n",
              "19  2.220446e-16  1.000000e+00  0.027027   0.0 -0.864396 -0.753404  0.270812\n",
              "20  2.220446e-16 -2.220446e-16 -1.000000   0.0 -0.665015 -0.358484 -0.435270\n",
              "21  2.220446e-16 -2.220446e-16  1.000000   0.0 -0.388854 -0.807140 -0.872919\n",
              "22  2.220446e-16 -2.220446e-16  0.027027  -1.0 -0.382043 -0.542142  0.096840\n",
              "23  2.220446e-16 -2.220446e-16  0.027027   1.0 -0.583901 -0.705558 -0.059463\n",
              "24  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.562229 -0.671329  0.020048\n",
              "25  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.667648  0.049269\n",
              "26  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.535604 -0.673169  0.423038\n",
              "27  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.699301  0.507985\n",
              "28  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.525697 -0.642989 -0.232756"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHAmeF3u9b1v"
      },
      "source": [
        "#dividindo randomicamente os dados de DAT em treino e teste\n",
        "train=DAT.sample(frac=0.8,random_state=None)\n",
        "test=DAT.drop(train.index)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3NrCwW9mUU"
      },
      "source": [
        "#Definindo as variaveis independentes\n",
        "x_train=train.iloc[:,[0,1,2,3]]\n",
        "x_test=test.iloc[:,[0,1,2,3]]\n",
        "X_OLD=DAT_OLD.iloc[:,[0,1,2,3]]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHep1do94DF",
        "outputId": "367f3060-d990-459b-db52-f8d28c6c2e0c"
      },
      "source": [
        "#variaveis independentes de treino e teste\n",
        "print(x_train)\n",
        "print (x_test)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Di            Do         L  Teta\n",
            "5  -6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "25  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "24  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "27  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "11  6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "21  2.220446e-16 -2.220446e-16  1.000000   0.0\n",
            "6  -6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "19  2.220446e-16  1.000000e+00  0.027027   0.0\n",
            "14  6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "10  6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "3  -6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "9   6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "26  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "16 -1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "28  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "15  6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "7  -6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "18  2.220446e-16 -1.000000e+00  0.027027   0.0\n",
            "20  2.220446e-16 -2.220446e-16 -1.000000   0.0\n",
            "17  1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "              Di            Do         L  Teta\n",
            "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "12  6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "13  6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "22  2.220446e-16 -2.220446e-16  0.027027  -1.0\n",
            "23  2.220446e-16 -2.220446e-16  0.027027   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4vJ0_69yiE",
        "outputId": "a14d3bf9-f281-4cf4-962c-2bd7bc31e3e5"
      },
      "source": [
        "#definindo a variavel dependente RL\n",
        "y_train=train.iloc[:,[4]]\n",
        "y_test=test.iloc[:,[4]]\n",
        "Y_OLD=DAT_OLD.iloc[:,[4]]\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          RL\n",
            "5  -0.983901\n",
            "25 -0.550464\n",
            "24 -0.562229\n",
            "1   0.180186\n",
            "2   0.334985\n",
            "27 -0.550464\n",
            "11  0.330031\n",
            "21 -0.388854\n",
            "6  -0.702786\n",
            "19 -0.864396\n",
            "14 -0.609907\n",
            "10  0.389474\n",
            "3   0.297833\n",
            "9   0.409288\n",
            "26 -0.535604\n",
            "16 -0.667492\n",
            "28 -0.525697\n",
            "15 -0.631579\n",
            "7  -0.571517\n",
            "4  -1.000000\n",
            "18  1.000000\n",
            "20 -0.665015\n",
            "17 -0.463777\n",
            "          RL\n",
            "0   0.117028\n",
            "8   0.161610\n",
            "12 -0.952941\n",
            "13 -0.760991\n",
            "22 -0.382043\n",
            "23 -0.583901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4haSAcEPN2S7"
      },
      "source": [
        "#define a rede neural\n",
        "#nessa rede vao ser usados 3 camadas: Input + hidden + output\n",
        "#o numero de neuronios da output eh 1, porque tem 1 resposta (FIE)\n",
        "#o numero de neuronios na hidden eh arbitrario. O artigo fez 12 neuronios nessa camada\n",
        "#funcao de ativicao eh a logistic, segundo o artigo\n",
        "model = MLPRegressor(solver='lbfgs',activation='logistic',alpha=1e-5,hidden_layer_sizes=(12),\n",
        "                    random_state=1, max_iter=1000)\n",
        "#o solver eh o lbfgs usado para metodos quasi-newton\n",
        "#coloquei 1000 itercoes"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhi90gVN3YV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229e9f61-4c6b-4189-e361-f3c5aa38d784"
      },
      "source": [
        "#treina a rede neural\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='logistic', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "             hidden_layer_sizes=12, learning_rate='constant',\n",
              "             learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "             power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
              "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-yOW0ZmN4e0"
      },
      "source": [
        "#usa a rede neural para treino e teste\n",
        "y_calc_train=model.predict(x_train)\n",
        "y_calc_test=model.predict(x_test)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfwjcMtN58a"
      },
      "source": [
        "#transforma a saida da rede em dataframe \n",
        "y_calc_train=pd.DataFrame(y_calc_train)\n",
        "y_calc_test=pd.DataFrame(y_calc_test)\n",
        "col_names=list(y_train)\n",
        "y_calc_train.columns = col_names\n",
        "y_calc_test.columns = col_names"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RboALKIN7as"
      },
      "source": [
        "#Desnormatizar os dados obtidos da rede neural\n",
        "y_calc_train=Original(y_calc_train,Y_OLD)\n",
        "y_calc_test=Original(y_calc_test,Y_OLD)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjoCPU8bN92O"
      },
      "source": [
        "#recupera os dados originais \n",
        "test=[]\n",
        "train=[]\n",
        "train=Original(y_train,Y_OLD)\n",
        "test=Original(y_test,Y_OLD)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiL9upNxN_RT"
      },
      "source": [
        "#Resposta para fazer o grafico (FIE-treino)\n",
        "resist_obs_train=[]\n",
        "resist_calc_train=[]\n",
        "resist_calc_train=y_calc_train['RL'].copy()\n",
        "resist_obs_train=train['RL'].copy()"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_g9O8DOAfQ"
      },
      "source": [
        "#Resposta para fazer o grafico (FIE-teste)\n",
        "resist_obs_test=[]\n",
        "resist_calc_test=[]\n",
        "resist_calc_test=y_calc_test['RL'].copy()\n",
        "resist_obs_test=test['RL'].copy()"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHCXQdoOBtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "1bb4ba20-f842-41d1-cf4b-1453f2430248"
      },
      "source": [
        "#expressa os dois dados em figura - EULER\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.scatter(resist_obs_test,resist_calc_test, s=10, c='b', marker=\"s\", label='teste')\n",
        "ax1.scatter(resist_obs_train,resist_calc_train, s=10, c='r', marker=\"o\", label='treino')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylabel('FIE Calc')\n",
        "plt.xlabel('FIE Obs')\n",
        "plt.show()"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxqGLrm6OCHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb71a52d-720f-4eff-f90b-bebea010a332"
      },
      "source": [
        "#checar a qualidade da regressao PARA TESTE\n",
        "mse=mean_squared_error(resist_obs_test,resist_calc_test)\n",
        "print(\"MSE teste=\",mse)\n",
        "R2=r2_score(resist_obs_test,resist_calc_test)\n",
        "print(\"R^2 teste=\",R2)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE teste= 6.789571151522231\n",
            "R^2 teste= 0.851662234709151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEznkoupODnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f3955a-a535-4bd0-aa72-b32aab42f229"
      },
      "source": [
        "#checar a qualidade da regressao PARA TREINO\n",
        "mse=mean_squared_error(resist_obs_train,resist_calc_train)\n",
        "print(\"MSE treino=\",mse)\n",
        "R2=r2_score(resist_obs_train,resist_calc_train)\n",
        "print(\"R^2 treino=\",R2)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE treino= 0.026579048667832582\n",
            "R^2 treino= 0.9996320765416036\n"
          ]
        }
      ]
    }
  ]
}