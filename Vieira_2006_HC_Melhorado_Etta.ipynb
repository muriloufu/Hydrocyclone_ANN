{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vieira_2006_HC_Melhorado_Etta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfQETtDF/XOI7pRCH7issX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muriloufu/Hydrocyclone_ANN/blob/main/Vieira_2006_HC_Melhorado_Etta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOID4YHpNewq"
      },
      "source": [
        "#bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "%matplotlib inline"
      ],
      "execution_count": 1268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHeAwtRNnC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "c0f0a5e2-891e-463c-f093-4a83fc765c54"
      },
      "source": [
        "#selecao do dataset\n",
        "path = 'https://github.com/muriloufu/Hydrocyclone_ANN/raw/main/Tese_LG_2006_01.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "df"
      ],
      "execution_count": 1269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>28.28</td>\n",
              "      <td>4493</td>\n",
              "      <td>65.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.30</td>\n",
              "      <td>4407</td>\n",
              "      <td>61.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>31.80</td>\n",
              "      <td>3997</td>\n",
              "      <td>72.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.20</td>\n",
              "      <td>3664</td>\n",
              "      <td>62.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>3697</td>\n",
              "      <td>54.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>10.50</td>\n",
              "      <td>3211</td>\n",
              "      <td>47.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>15.04</td>\n",
              "      <td>3257</td>\n",
              "      <td>61.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>17.16</td>\n",
              "      <td>3016</td>\n",
              "      <td>54.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>29.00</td>\n",
              "      <td>2416</td>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1789</td>\n",
              "      <td>69.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>32.68</td>\n",
              "      <td>1587</td>\n",
              "      <td>72.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.72</td>\n",
              "      <td>1467</td>\n",
              "      <td>63.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1679</td>\n",
              "      <td>68.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>14.10</td>\n",
              "      <td>1177</td>\n",
              "      <td>59.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>16.54</td>\n",
              "      <td>1071</td>\n",
              "      <td>62.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>16.19</td>\n",
              "      <td>1001</td>\n",
              "      <td>56.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.61</td>\n",
              "      <td>6435</td>\n",
              "      <td>62.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.7</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1109</td>\n",
              "      <td>60.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>42.54</td>\n",
              "      <td>2866</td>\n",
              "      <td>76.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.3</td>\n",
              "      <td>10.5</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>12.43</td>\n",
              "      <td>1671</td>\n",
              "      <td>66.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>117</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.65</td>\n",
              "      <td>2744</td>\n",
              "      <td>55.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>228</td>\n",
              "      <td>14.5</td>\n",
              "      <td>20.11</td>\n",
              "      <td>1525</td>\n",
              "      <td>49.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.22</td>\n",
              "      <td>2245</td>\n",
              "      <td>63.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.96</td>\n",
              "      <td>1801</td>\n",
              "      <td>61.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1904</td>\n",
              "      <td>62.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Di    Do    L  Teta     RL    Eu   Etta\n",
              "0   4.8   6.6  142  11.2  28.28  4493  65.18\n",
              "1   4.8   6.6  142  17.8  29.30  4407  61.76\n",
              "2   4.8   6.6  207  11.2  31.80  3997  72.47\n",
              "3   4.8   6.6  207  17.8  31.20  3664  62.23\n",
              "4   4.8   9.6  142  11.2  10.24  3697  54.06\n",
              "5   4.8   9.6  142  17.8  10.50  3211  47.30\n",
              "6   4.8   9.6  207  11.2  15.04  3257  61.52\n",
              "7   4.8   9.6  207  17.8  17.16  3016  54.30\n",
              "8   7.8   6.6  142  11.2  29.00  2416  74.59\n",
              "9   7.8   6.6  142  17.8  33.00  1789  69.00\n",
              "10  7.8   6.6  207  11.2  32.68  1587  72.32\n",
              "11  7.8   6.6  207  17.8  31.72  1467  63.40\n",
              "12  7.8   9.6  142  11.2  11.00  1679  68.82\n",
              "13  7.8   9.6  142  17.8  14.10  1177  59.83\n",
              "14  7.8   9.6  207  11.2  16.54  1071  62.42\n",
              "15  7.8   9.6  207  17.8  16.19  1001  56.44\n",
              "16  3.9   8.1  174  14.5  15.61  6435  62.84\n",
              "17  8.7   8.1  174  14.5  18.90  1109  60.35\n",
              "18  6.3   5.7  174  14.5  42.54  2866  76.73\n",
              "19  6.3  10.5  174  14.5  12.43  1671  66.00\n",
              "20  6.3   8.1  117  14.5  15.65  2744  55.61\n",
              "21  6.3   8.1  228  14.5  20.11  1525  49.17\n",
              "22  6.3   8.1  174   9.0  20.22  2245  63.44\n",
              "23  6.3   8.1  174  20.0  16.96  1801  61.14\n",
              "24  6.3   8.1  174  14.5  17.50  1904  62.74"
            ]
          },
          "metadata": {},
          "execution_count": 1269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_18br6NreR"
      },
      "source": [
        "# funcao normatiza dados\n",
        "def Normatiza(x):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x[i].max()\n",
        "        min_x=x[i].min()\n",
        "        x[i]=2*((x[i]-min_x)/(max_x-min_x))-1\n",
        "    return x"
      ],
      "execution_count": 1270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6NFycRWNtEI"
      },
      "source": [
        "# funcao retorna os dados a forma original - xi ISOLADO DA FUNCAO: NORMATIZA(X)\n",
        "def Original(x,x_old):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x_old[i].max()\n",
        "        min_x=x_old[i].min()\n",
        "        x[i]=((x[i]+1)/2)*(max_x-min_x)+min_x\n",
        "    return x"
      ],
      "execution_count": 1271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRm1LcrNuMk"
      },
      "source": [
        "DAT_OLD=[] #Criar um dataframe em branco\n",
        "DAT_OLD=df.copy() #No dataframe em branco esta colocando os dados de df (dataframe que chamou no inicio)\n",
        "DAT=Normatiza(df) #No dataframe DAT coloca o dataframe df normatizado"
      ],
      "execution_count": 1272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "iWlBoKYCCTZD",
        "outputId": "c9b6c269-43ff-46a9-f017-d3a4f703f93c"
      },
      "source": [
        "DAT #mostra o dataframe DAT que Ã© o df normatizado"
      ],
      "execution_count": 1273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.117028</td>\n",
              "      <td>0.285241</td>\n",
              "      <td>0.215087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.180186</td>\n",
              "      <td>0.253589</td>\n",
              "      <td>-0.017329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.334985</td>\n",
              "      <td>0.102687</td>\n",
              "      <td>0.710499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.297833</td>\n",
              "      <td>-0.019875</td>\n",
              "      <td>0.014611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.540605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.983901</td>\n",
              "      <td>-0.186603</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.702786</td>\n",
              "      <td>-0.169672</td>\n",
              "      <td>-0.033639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.571517</td>\n",
              "      <td>-0.258373</td>\n",
              "      <td>-0.524295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.161610</td>\n",
              "      <td>-0.479205</td>\n",
              "      <td>0.854570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.409288</td>\n",
              "      <td>-0.709974</td>\n",
              "      <td>0.474686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>-0.784321</td>\n",
              "      <td>0.700306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.330031</td>\n",
              "      <td>-0.828487</td>\n",
              "      <td>0.094122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.952941</td>\n",
              "      <td>-0.750460</td>\n",
              "      <td>0.462453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.760991</td>\n",
              "      <td>-0.935223</td>\n",
              "      <td>-0.148488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.609907</td>\n",
              "      <td>-0.974236</td>\n",
              "      <td>0.027523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.631579</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.378865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.667492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.056065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.463777</td>\n",
              "      <td>-0.960250</td>\n",
              "      <td>-0.113150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.313581</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.864396</td>\n",
              "      <td>-0.753404</td>\n",
              "      <td>0.270812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.665015</td>\n",
              "      <td>-0.358484</td>\n",
              "      <td>-0.435270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.388854</td>\n",
              "      <td>-0.807140</td>\n",
              "      <td>-0.872919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.382043</td>\n",
              "      <td>-0.542142</td>\n",
              "      <td>0.096840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.583901</td>\n",
              "      <td>-0.705558</td>\n",
              "      <td>-0.059463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.667648</td>\n",
              "      <td>0.049269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Di            Do         L  Teta        RL        Eu      Etta\n",
              "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.117028  0.285241  0.215087\n",
              "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6  0.180186  0.253589 -0.017329\n",
              "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6  0.334985  0.102687  0.710499\n",
              "3  -6.250000e-01 -6.250000e-01  0.621622   0.6  0.297833 -0.019875  0.014611\n",
              "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6 -1.000000 -0.007729 -0.540605\n",
              "5  -6.250000e-01  6.250000e-01 -0.549550   0.6 -0.983901 -0.186603 -1.000000\n",
              "6  -6.250000e-01  6.250000e-01  0.621622  -0.6 -0.702786 -0.169672 -0.033639\n",
              "7  -6.250000e-01  6.250000e-01  0.621622   0.6 -0.571517 -0.258373 -0.524295\n",
              "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.161610 -0.479205  0.854570\n",
              "9   6.250000e-01 -6.250000e-01 -0.549550   0.6  0.409288 -0.709974  0.474686\n",
              "10  6.250000e-01 -6.250000e-01  0.621622  -0.6  0.389474 -0.784321  0.700306\n",
              "11  6.250000e-01 -6.250000e-01  0.621622   0.6  0.330031 -0.828487  0.094122\n",
              "12  6.250000e-01  6.250000e-01 -0.549550  -0.6 -0.952941 -0.750460  0.462453\n",
              "13  6.250000e-01  6.250000e-01 -0.549550   0.6 -0.760991 -0.935223 -0.148488\n",
              "14  6.250000e-01  6.250000e-01  0.621622  -0.6 -0.609907 -0.974236  0.027523\n",
              "15  6.250000e-01  6.250000e-01  0.621622   0.6 -0.631579 -1.000000 -0.378865\n",
              "16 -1.000000e+00 -2.220446e-16  0.027027   0.0 -0.667492  1.000000  0.056065\n",
              "17  1.000000e+00 -2.220446e-16  0.027027   0.0 -0.463777 -0.960250 -0.113150\n",
              "18  2.220446e-16 -1.000000e+00  0.027027   0.0  1.000000 -0.313581  1.000000\n",
              "19  2.220446e-16  1.000000e+00  0.027027   0.0 -0.864396 -0.753404  0.270812\n",
              "20  2.220446e-16 -2.220446e-16 -1.000000   0.0 -0.665015 -0.358484 -0.435270\n",
              "21  2.220446e-16 -2.220446e-16  1.000000   0.0 -0.388854 -0.807140 -0.872919\n",
              "22  2.220446e-16 -2.220446e-16  0.027027  -1.0 -0.382043 -0.542142  0.096840\n",
              "23  2.220446e-16 -2.220446e-16  0.027027   1.0 -0.583901 -0.705558 -0.059463\n",
              "24  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.667648  0.049269"
            ]
          },
          "metadata": {},
          "execution_count": 1273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHAmeF3u9b1v"
      },
      "source": [
        "#dividindo randomicamente os dados de DAT em treino e teste\n",
        "train=DAT.sample(frac=0.8,random_state=None)\n",
        "test=DAT.drop(train.index)"
      ],
      "execution_count": 1274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3NrCwW9mUU"
      },
      "source": [
        "#Definindo as variaveis independentes\n",
        "x_train=train.iloc[:,[0,1,2,3]]\n",
        "x_test=test.iloc[:,[0,1,2,3]]\n",
        "X_OLD=DAT_OLD.iloc[:,[0,1,2,3]]"
      ],
      "execution_count": 1275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHep1do94DF",
        "outputId": "de7df7a7-0ab1-4881-d877-bc9267a20fd8"
      },
      "source": [
        "#variaveis independentes de treino e teste\n",
        "print(x_train)\n",
        "print (x_test)"
      ],
      "execution_count": 1276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Di            Do         L  Teta\n",
            "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "20  2.220446e-16 -2.220446e-16 -1.000000   0.0\n",
            "6  -6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "14  6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "7  -6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "11  6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "18  2.220446e-16 -1.000000e+00  0.027027   0.0\n",
            "22  2.220446e-16 -2.220446e-16  0.027027  -1.0\n",
            "13  6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "23  2.220446e-16 -2.220446e-16  0.027027   1.0\n",
            "19  2.220446e-16  1.000000e+00  0.027027   0.0\n",
            "10  6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "17  1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "24  2.220446e-16 -2.220446e-16  0.027027   0.0\n",
            "16 -1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "21  2.220446e-16 -2.220446e-16  1.000000   0.0\n",
            "3  -6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "       Di     Do         L  Teta\n",
            "4  -0.625  0.625 -0.549550  -0.6\n",
            "5  -0.625  0.625 -0.549550   0.6\n",
            "9   0.625 -0.625 -0.549550   0.6\n",
            "12  0.625  0.625 -0.549550  -0.6\n",
            "15  0.625  0.625  0.621622   0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4vJ0_69yiE",
        "outputId": "37adb250-97eb-454c-ea22-5e044eeccb61"
      },
      "source": [
        "#definindo a variavel dependente Etta\n",
        "y_train=train.iloc[:,[6]]\n",
        "y_test=test.iloc[:,[6]]\n",
        "Y_OLD=DAT_OLD.iloc[:,[6]]\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": 1277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Etta\n",
            "1  -0.017329\n",
            "20 -0.435270\n",
            "6  -0.033639\n",
            "14  0.027523\n",
            "7  -0.524295\n",
            "11  0.094122\n",
            "18  1.000000\n",
            "22  0.096840\n",
            "13 -0.148488\n",
            "23 -0.059463\n",
            "19  0.270812\n",
            "10  0.700306\n",
            "2   0.710499\n",
            "17 -0.113150\n",
            "24  0.049269\n",
            "16  0.056065\n",
            "21 -0.872919\n",
            "3   0.014611\n",
            "8   0.854570\n",
            "0   0.215087\n",
            "        Etta\n",
            "4  -0.540605\n",
            "5  -1.000000\n",
            "9   0.474686\n",
            "12  0.462453\n",
            "15 -0.378865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4haSAcEPN2S7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77249a42-ecdc-4d8d-8531-4e0471c8ed35"
      },
      "source": [
        "#define a rede neural\n",
        "#nessa rede vao ser usados 3 camadas: Input + hidden + output\n",
        "#o numero de neuronios da output eh 1, porque tem 1 resposta (FIE)\n",
        "#o numero de neuronios na hidden eh arbitrario. O artigo fez 12 neuronios nessa camada\n",
        "#funcao de ativicao eh a logistic, segundo o artigo\n",
        "#model = MLPRegressor(random_state=1,solver='lbfgs',activation='tanh', learning_rate = 'adaptive', alpha=1e-5, \n",
        "#                     hidden_layer_sizes= tuple(12 for _ in range(5)))\n",
        "\n",
        "\n",
        "# define a rede neural \n",
        "model = Sequential()\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=1))\n",
        "model.add(Activation('linear'))\n",
        "model.compile(\n",
        "  loss='mean_squared_error',\n",
        "  optimizer='adam'\n",
        ")\n",
        "model.fit(x_train, y_train, epochs=500, batch_size=100)"
      ],
      "execution_count": 1278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.2789\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1409\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1307\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1340\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1386\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1340\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1236\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1155\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1128\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1142\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1171\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1191\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1190\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1167\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1138\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1115\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1101\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1090\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1078\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1068\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1063\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1062\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1060\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1052\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1038\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1019\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0997\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0975\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0954\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0934\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0912\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0884\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0852\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0818\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0780\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0738\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0690\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0637\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0580\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0524\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0466\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0407\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0352\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0303\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0260\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0227\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0204\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0190\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0181\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0175\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0166\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0153\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0136\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0118\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0102\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0090\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0079\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0071\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0064\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0058\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0053\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0048\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0042\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0037\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0028\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0021\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0018\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0015\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.4116e-04\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.3459e-04\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3650e-04\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4824e-04\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9083e-04\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5539e-04\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.3710e-04\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2893e-04\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1410e-04\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.9786e-04\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.7580e-04\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4138e-04\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.0038e-04\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4582e-04\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9173e-04\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5634e-04\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4059e-04\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5094e-04\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9117e-04\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8590e-04\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7833e-04\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7424e-04\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.6216e-04\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.6002e-04\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6698e-04\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6318e-04\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3544e-04\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1773e-04\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7485e-04\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1181e-04\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2177e-04\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7480e-04\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7167e-04\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2467e-05\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8539e-04\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6848e-04\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5691e-04\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9347e-05\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0339e-04\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8407e-04\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4131e-04\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1056e-05\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1123e-05\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1169e-04\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1573e-04\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6058e-05\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3082e-05\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1965e-05\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3398e-05\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7813e-05\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0998e-05\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2295e-05\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4004e-05\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8661e-05\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5592e-05\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1960e-05\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4165e-05\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5033e-05\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6742e-05\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4551e-05\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1269e-05\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0125e-05\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4041e-06\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6367e-05\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2464e-05\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2176e-05\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6171e-05\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2363e-06\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.5548e-06\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 6.2533e-06\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.5370e-06\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2741e-05\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3998e-05\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2922e-05\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0281e-05\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2037e-06\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6177e-06\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9702e-06\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3298e-06\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5050e-06\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2669e-06\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4155e-06\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8868e-06\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.7246e-06\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0147e-05\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3571e-05\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8746e-05\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6966e-05\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0475e-05\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3303e-05\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0244e-04\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7001e-04\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8416e-04\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6757e-04\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2576e-04\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0011\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9973e-04\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9758e-04\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0777e-05\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3287e-05\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8447e-04\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3727e-04\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5496e-04\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0644e-05\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6741e-05\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9017e-04\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0918e-04\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0942e-04\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8213e-05\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3865e-05\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2467e-04\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8641e-04\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1371e-04\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5057e-05\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4252e-05\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4623e-05\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1350e-04\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3742e-05\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8947e-06\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0328e-05\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3002e-05\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0001e-05\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1000e-05\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.8504e-06\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1548e-06\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8520e-05\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3291e-05\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1144e-05\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.5368e-06\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0092e-07\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0625e-05\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3846e-05\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4512e-05\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3184e-05\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1238e-06\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4005e-07\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.8082e-06\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4478e-05\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4488e-05\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5536e-06\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1800e-06\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7794e-08\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5403e-06\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6081e-06\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.7822e-06\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.7200e-06\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5288e-06\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4159e-06\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9995e-08\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5065e-07\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4170e-06\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1096e-06\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8655e-06\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4757e-06\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2811e-06\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8536e-06\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9839e-07\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8036e-08\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8875e-08\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4048e-07\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0609e-06\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7289e-06\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3247e-06\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7967e-06\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1476e-06\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4158e-06\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6554e-06\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9307e-06\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.3123e-06\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8880e-06\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7736e-06\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1460e-06\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2835e-06\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2654e-05\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.8037e-05\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6790e-05\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.1243e-05\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.5513e-05\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.0663e-04\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7666e-04\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9425e-04\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.8544e-04\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.7098e-04\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0015\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.9739e-04\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3374e-04\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.5106e-06\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0468e-04\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7973e-04\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.3604e-04\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.0942e-04\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.8989e-05\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.6936e-05\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2230e-04\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4942e-04\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3904e-04\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2540e-06\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3481e-05\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2024e-04\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7364e-04\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.7209e-05\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3148e-05\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0346e-04\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4325e-04\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5598e-05\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6075e-05\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.1292e-05\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1751e-04\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2670e-04\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0668e-04\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4403e-04\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5980e-04\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7816e-04\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.6505e-04\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.8302e-04\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6316e-04\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3105e-04\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4991e-04\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9315e-05\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0897e-05\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4666e-04\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3591e-04\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2024e-04\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1576e-04\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.8641e-05\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5433e-05\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 5.8576e-05\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0460e-04\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1283e-04\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4153e-05\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7482e-05\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4201e-06\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4458e-05\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3785e-05\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6541e-05\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9041e-05\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0206e-05\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.8064e-06\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9497e-06\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7306e-05\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2610e-05\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.5204e-05\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4849e-05\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1760e-05\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.8979e-06\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.6531e-06\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4353e-06\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4062e-05\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7237e-05\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5913e-05\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0918e-05\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7569e-06\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5588e-07\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6481e-07\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7203e-06\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.4649e-06\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5054e-06\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.0603e-06\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7508e-06\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0358e-06\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9304e-06\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3727e-07\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.2501e-07\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0307e-06\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8322e-06\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8222e-06\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7743e-06\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4034e-06\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5755e-06\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2443e-06\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6078e-06\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8519e-06\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1829e-06\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6590e-06\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2766e-06\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.7391e-07\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1090e-07\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.7532e-07\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8268e-07\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5148e-07\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6993e-08\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.5003e-08\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 9.0089e-08\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0735e-07\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1129e-07\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8434e-08\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.4677e-08\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.9905e-08\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3297e-08\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0976e-08\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.6050e-08\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.0640e-08\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4007e-07\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3803e-07\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0557e-07\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0552e-07\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2662e-06\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3370e-06\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.4397e-06\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5892e-06\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7018e-05\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3979e-05\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9412e-05\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4048e-04\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8956e-04\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.6380e-04\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0011\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0017\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0023\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0018\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.8300e-04\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1167e-04\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.7092e-04\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.5044e-04\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.3497e-05\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7291e-04\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.3927e-04\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.6092e-04\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.0041e-04\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4412e-04\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.6224e-04\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.1918e-04\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3408e-05\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0727e-04\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8952e-04\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7322e-04\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7327e-05\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2462e-04\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1107e-04\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6489e-05\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7779e-06\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0322e-04\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2004e-04\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7141e-05\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9665e-05\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.8425e-05\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4389e-05\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0035e-05\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3712e-05\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.2829e-05\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4459e-05\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.0937e-07\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3080e-05\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.3101e-05\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9330e-05\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2164e-06\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1855e-05\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9835e-05\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0059e-05\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1849e-06\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5459e-05\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.7609e-05\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2590e-06\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.2556e-06\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0702e-05\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1541e-05\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8052e-06\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6540e-06\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.1632e-06\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.5352e-06\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8924e-06\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1306e-06\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.4690e-06\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1457e-06\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6785e-06\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1883e-06\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4956e-06\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.0629e-06\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0165e-06\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9299e-06\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2424e-05\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7651e-05\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3003e-05\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2330e-05\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.9344e-05\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.5991e-05\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1618e-04\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8040e-04\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8230e-04\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3923e-04\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6259e-04\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5370e-04\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0013\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0014\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0013\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.5827e-04\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9435e-04\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5960e-06\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3324e-04\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4046e-04\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.6706e-04\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7326e-04\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5948e-05\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.4737e-06\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6238e-04\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9816e-04\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3089e-04\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.0796e-05\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3807e-06\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4533e-05\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7250e-04\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.2297e-04\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3980e-05\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1483e-06\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9840e-05\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0265e-04\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.8206e-05\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.3927e-06\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2299e-05\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2244e-05\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.8607e-05\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4337e-05\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.2402e-07\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4308e-05\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6189e-05\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1660e-05\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.2916e-06\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.1210e-07\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2598e-05\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3182e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c7ea57d90>"
            ]
          },
          "metadata": {},
          "execution_count": 1278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhi90gVN3YV"
      },
      "source": [
        "#treina a rede neural\n",
        "#model.fit(x_train, y_train)"
      ],
      "execution_count": 1279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-yOW0ZmN4e0"
      },
      "source": [
        "#usa a rede neural para treino e teste\n",
        "y_calc_train=model.predict(x_train)\n",
        "y_calc_test=model.predict(x_test)"
      ],
      "execution_count": 1280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfwjcMtN58a"
      },
      "source": [
        "#transforma a saida da rede em dataframe \n",
        "y_calc_train=pd.DataFrame(y_calc_train)\n",
        "y_calc_test=pd.DataFrame(y_calc_test)\n",
        "col_names=list(y_train)\n",
        "y_calc_train.columns = col_names\n",
        "y_calc_test.columns = col_names"
      ],
      "execution_count": 1281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RboALKIN7as"
      },
      "source": [
        "#Desnormatizar os dados obtidos da rede neural\n",
        "y_calc_train=Original(y_calc_train,Y_OLD)\n",
        "y_calc_test=Original(y_calc_test,Y_OLD)"
      ],
      "execution_count": 1282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjoCPU8bN92O"
      },
      "source": [
        "#recupera os dados originais \n",
        "test=[]\n",
        "train=[]\n",
        "train=Original(y_train,Y_OLD)\n",
        "test=Original(y_test,Y_OLD)"
      ],
      "execution_count": 1283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiL9upNxN_RT"
      },
      "source": [
        "#Resposta para fazer o grafico (Etta-treino)\n",
        "resist_obs_train=[]\n",
        "resist_calc_train=[]\n",
        "resist_calc_train=y_calc_train['Etta'].copy()\n",
        "resist_obs_train=train['Etta'].copy()"
      ],
      "execution_count": 1284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_g9O8DOAfQ"
      },
      "source": [
        "#Resposta para fazer o grafico (Etta-teste)\n",
        "resist_obs_test=[]\n",
        "resist_calc_test=[]\n",
        "resist_calc_test=y_calc_test['Etta'].copy()\n",
        "resist_obs_test=test['Etta'].copy()"
      ],
      "execution_count": 1285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHCXQdoOBtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f5f53b12-ce48-4f91-817c-45123db27314"
      },
      "source": [
        "#expressa os dois dados em figura - ETTA\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.scatter(resist_obs_test,resist_calc_test, s=10, c='b', marker=\"s\", label='teste')\n",
        "ax1.scatter(resist_obs_train,resist_calc_train, s=10, c='r', marker=\"o\", label='treino')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylabel('Etta')\n",
        "plt.xlabel('Etta')\n",
        "plt.show()"
      ],
      "execution_count": 1286,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAX20lEQVR4nO3dfWwd9Z3v8feHPBkHJ4TgRuFmW1JEs6W0DWBSUBrabBaHh8pAVVDTB6Hu0uQPwparChK6fQDd3tts1aqwlEaElkCfrA3RQq2rXmoUUXpVXRBOiCALLOEhuXWAxKSlefAlAfO9f8wxObGPHSfxnOM5v89LOpr5zTnj852M8vH4NzO/UURgZmbpOKHWBZiZWXU5+M3MEuPgNzNLjIPfzCwxDn4zs8SMr3UBI3HqqafG6aefXusyzMwKZePGjW9ERPPA5YUI/tNPP52urq5al2FmViiStlda7q4eM7PEOPjNzBLj4DczS0wh+vgrefvtt+nu7uatt96qdSk10dDQwKxZs5gwYUKtSzGzgils8Hd3d9PU1MTpp5+OpFqXU1URwe7du+nu7mb27Nm1LsfMCqawXT1vvfUW06dPTy70ASQxffr0ZP/aMbPjU9jgB5IM/X4pb7tZMjo6YPnybDqKCh38ZmZ1q6MDliyBu+7KpqMY/g7+Y/Tmm2/yk5/85JjWvf322+nt7R3lisysrnR2Qn9O9PZm7VHi4D9GDn4zy1VrKzQ2ZvONjVl7lBT2qp5aW7lyJS+99BJz587l4osv5n3vex/r1q3jwIEDXHXVVdx2223s37+fa665hu7ubvr6+vjWt77Fzp07efXVV1m4cCGnnnoqjz76KJ2dnXznO9/hwIEDnHHGGaxdu5aTTjqp1ptoZrXU1gbt7dmRfmtr1h4tETHmX+edd14M9Oyzzw5aNpympgg49GpqOqrVB3nllVfiIx/5SERE/O53v4uvfvWr8e6770ZfX19cfvnl8dhjj8X69evjuuuue2+dN998MyIiPvCBD0RPT09ERPT09MSCBQti3759ERGxatWquO2220ZUw9H+G5hZWoCuqJCpyRzx7907fPt4dHZ20tnZyTnnnAPAvn372Lp1KwsWLODrX/86K1as4DOf+QwLFiwYtO7jjz/Os88+y/z58wE4ePAgF1544egVZ2Y2QDLBn6eI4JZbbmHZsmWD3tu0aRO//e1v+eY3v8miRYv49re/PWjdiy++mPb29mqVa2aJ88ndY9TU1MTe0p8Nixcv5t5772Xfvn0A7Nixg127dvHqq6/S2NjIl770JW666SY2bdo0aN0LLriAP/7xj7z44osA7N+/nxdeeKEGW2RmqUjmiL+p6fDunaam4/t506dPZ/78+Zx99tlceumlfOELX3ivi+akk07il7/8JS+++CI33XQTJ5xwAhMmTGD16tUALF26lEsuuYTTTjuNRx99lPvuu48lS5Zw4MABAL773e/yoQ996PgKNDMbgrL+/7GtpaUlBj6I5bnnnuPDH/5wjSoaG/xvYGbDkbQxIloGLs/tiF/SHODfyhZ9EPg2cDLwVaCntPwbEfHbvOowM7PD5Rb8EfGfwFwASeOAHcCDwFeAH0XED/L6bjMzG1q1Tu4uAl6KiIrPfzQzs+qpVvB/Hii/XnG5pKcl3StpWqUVJC2V1CWpq6enp9JHzMzsGOQe/JImAm3AA6VFq4EzyLqBXgN+WGm9iFgTES0R0dLc3Jx3mWZmxyanoZPzVI0j/kuBTRGxEyAidkZEX0S8C9wDzKtCDWZmoy/HoZPzVI3gX0JZN4+kmWXvXQVsqUINo+5YRud89dVX+dznPpdTRWZWdTkOnZynXINf0mTgYuDfyxZ/X9Izkp4GFgL/Nc8a8jJU8L/zzjtDrnPaaaexfv36PMsys2rKcejkPOUa/BGxPyKmR8Rfy5Z9OSI+GhEfi4i2iHgtzxryUj4s8/nnn8+CBQtoa2vjrLPOoq+vj5tuuonzzz+fj33sY9x9990AbNu2jbPPPhuA++67j89+9rNccsklnHnmmdx8883v/ez29nY++tGPcvbZZ7NixYqabJ+ZjUD/0MnXX59NR3Po5BwlM2QDkPW/jdLY1qtWrWLLli1s3ryZ3//+91x++eVs2bKF2bNns2bNGqZOncqTTz7JgQMHmD9/Pq2trYOek7t582aeeuopJk2axJw5c7jhhhsYN24cK1asYOPGjUybNo3W1lYeeughrrzyyuOq18xy0tZWmMDvl84gbTmfhJk3bx6zZ88GsmGaf/7znzN37lw+8YlPsHv3brZu3TponUWLFjF16lQaGho466yz2L59O08++SSf/vSnaW5uZvz48Xzxi1/kD3/4w6jWamZpS+eIv9JJmFH8LT158uT35iOCO++8k8WLFx/2mW3bth3WnjRp0nvz48aNG/b8gJnZaEnniH+UT8KUD6080OLFi1m9ejVvv/02AC+88AL79+8f0c+dN28ejz32GG+88QZ9fX20t7fzqU996rhqNTMrl84R/yg/v7J8WOYTTzyRGTNmvPfeddddx7Zt2zj33HOJCJqbm3nooYdG9HNnzpzJqlWrWLhwIRHB5ZdfzhVXXHFctZqZlfOwzAXmfwMzG85QwzKn09VjZmaAg9/MLDmFDv4idFPlJeVtN7PjU9jgb2hoYPfu3UkGYESwe/duGhoaal2KmRVQYa/qmTVrFt3d3aQ6Vn9DQwOzZs2qdRlmVkCFDf4JEya8d6esmdmwOjqgNGYWy5YVboiF0VbY4DczG5GODrj6ajh4MGtv2ADr1iUd/oXt4zczG5HOzkOhD3DgQGHGzc+Lg9/M6ltrK0yceKg9aVJhxs3Pi7t6zKy+tbXBAw+4j7+Mg9/M6l8Bx8zPk7t6zMwS4+A3M0uMg9/MLDEOfjOzxDj4zcwS4+A3M0uMg9/MLDEOfjOzxDj4zcwS4+A3M0tMbsEvaY6kzWWvPZJulHSKpEckbS1Np+VVg5mZDZZb8EfEf0bE3IiYC5wH9AIPAiuBDRFxJrCh1DYzsyqpVlfPIuCliNgOXAHcX1p+P3BllWowMzOqF/yfB9pL8zMi4rXS/OvAjEorSFoqqUtSV6rP1TUzy0PuwS9pItAGPDDwvYgIICqtFxFrIqIlIlqam5tzrtLMLB3VOOK/FNgUETtL7Z2SZgKUpruqUIOZmZVUI/iXcKibB6ADuLY0fy3wmyrUYGZmJbkGv6TJwMXAv5ctXgVcLGkr8PeltpmZVUmuj16MiP3A9AHLdpNd5WNmZjXgO3fNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M8vFlCkgHXpNmVLriqyfg9/McrF37/Btqx0Hv5lZYhz8ZmaJcfCbWS6amoZvW+3k+iAWM0vXnj21rsCG4iN+M7PEOPjNzBLj4DczS4yD38wsMQ5+s3rX0QHLl2dTMxz8ZvWtowOWLIG77sqmDn/DwW9W3zo7obc3m+/tzdqWPAe/WT1rbYXGxmy+sTFrW/J8A5dZPWtrg/b27Ei/tTVrW/Ic/Gb1rq3NgW+HybWrR9LJktZLel7Sc5IulHSrpB2SNpdel+VZg1ld8xU7dgzyPuK/A3g4Ij4naSLQCCwGfhQRP8j5u83qW/8VO729sHZt1qXjI3sbgdyO+CVNBS4CfgYQEQcj4s28vs8sOb5ix45Rnl09s4EeYK2kpyT9VNLk0nvLJT0t6V5J0yqtLGmppC5JXT09PTmWaVZQvmLHjpEiIp8fLLUAjwPzI+IJSXcAe4AfA28AAfw3YGZE/MNwP6ulpSW6urpyqdOs0Do6fMWODUnSxohoGbg8zz7+bqA7Ip4otdcDKyNiZ1lR9wD/M8cazOqbr9ixY5BbV09EvA78SdKc0qJFwLOSZpZ97CpgS141mJnZYHlf1XMD8KvSFT0vA18B/lXSXLKunm3AspxrMDOzMrkGf0RsBgb2L305z+80M7PheaweM7PEOPjNzBIz4q6e0vX2ZwIN/csi4g95FGVmxTVlCuzde6jd1AR79tSuHhtsRMEv6Trga8AsYDNwAfB/gL/LrzSzOlbH19+Xh36lttXeSLt6vgacD2yPiIXAOYCHXzA7Fh0dcPXV2VOxrr7aA6xZ1Y00+N+KiLcAJE2KiOeBOUdYx8wquftuOHgwmz94MGubVdFI+/i7JZ0MPAQ8IukvwPb8yjKzompqGtzHb2PLiII/Iq4qzd4q6VFgKvC/cqvKrJ4tWwYbNsCBAzBpUtauIz6RO/aNqKtH0i/65yPisYjoAO7NrSqzelHpQSltbbBuHVx/fTats5O7NvaNtKvnI+UNSeOA80a/HLM68s//DN//PrzzzuAHpXhwNauhYYNf0i3AN4ATJfX/ASfgIHBPzrWZFU//ZZpTp8K//Av09WXL+x+U4rC3MWDY4I+I7wHfk/S9iLilSjWZFVP5oxDHjTsU+gDjx/tBKTZmjPRyznkDF0jaMMq1mBVb+aMQ+/qysIfsl8DNN/to38aMI3X1NACTgVNLQzao9NYU4L/kXJtZcXR0wCuvwMSJ2bX5jY1w443w17/W5d25VmxHOrm7DLgROA3YVLa8/xGKZlbexTNpElx2WXaJpsPexqgj9fHfAdwh6YaIuLNKNZkVS3kXz4EDMHu2Q9/GtGH7+CXdDBARd0q6esB7/yPPwszGrIHX5re2Zl07kE19EtfGOEXE0G9KmyLi3IHzldp5amlpia6urmp8lVll5Zdp3n57doTf2Hjo2vw6Hm3TikvSxogY+BTEI/bxa4j5Sm2z+lTehz9+fHZDFhx+bb5vyLICOdLlnDHEfKW2WX0q78N/553s8kxwt44V1pGO+D9eumNXDL57t2Ho1cwKrrzrprU1G3Khv3vHl2lawR3pqp5x1SrEbMwo79rpH2Onvd19+FY3RvzMXbNklHft9Pfj//jHDnyrGyMdssEsHb480+qcj/jNBmprc9eO1TUHv6XpSNfd+/JMq2Pu6rH09J+8veuubFr+dCyzBOQa/JJOlrRe0vOSnpN0oaRTJD0iaWtpOi3PGswGqXTy1iwheR/x3wE8HBF/C3wceA5YCWyIiDOBDaW2WfX45K0lLrfglzQVuAj4GUBEHIyIN4ErgPtLH7sfuDKvGsyAwYOq9Z+8vf76w5+Da5aIYQdpO64fLM0F1gDPkh3tbwS+BuyIiJNLnxHwl/72gPWXAksB3v/+95+3ffv2XOq0Old+M1b5oGpmCRhqkLY8u3rGA+cCqyPiHGA/A7p1IvutU/E3T0SsiYiWiGhpbm7OsUyra+7PNxskz+DvBroj4olSez3ZL4KdkmYClKa7cqzBUuf+fLNBcgv+iHgd+JOkOaVFi8i6fTqAa0vLrgV+k1cNZu7PNxss7xu4bgB+JWki8DLwFbJfNusk/SOwHbgm5xosdb4Zy+wwuQZ/RGwGBp1YIDv6NzOzGvCdu2ZmiXHwm5klxsFvZpYYB7+NuilTQDr0mjKl1hWZWTkHv426vXuHb5tZbTn4zcwS4+A3M0uMg99GXVPT8G0zqy0/etFG3Z49ta7AzIbjI34zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfjl5HByxfnk3NrHAc/HZ0OjpgyRK4665s6vA3KxwHvx2dzk7o7c3me3uztpkVSq7BL2mbpGckbZbUVVp2q6QdpWWbJV2WZw02ylpbobExm29szNpmVijVeObuwoh4Y8CyH0XED6rw3Tba2tqgvT070m9tzdpmVih+2LodvbY2B75ZgeXdxx9Ap6SNkpaWLV8u6WlJ90qaVmlFSUsldUnq6unpyblMM7N05B38n4yIc4FLgeslXQSsBs4A5gKvAT+stGJErImIlohoaW5uzrlMM7N05Br8EbGjNN0FPAjMi4idEdEXEe8C9wDz8qzBzMwOl1vwS5osqal/HmgFtkiaWfaxq4AtedVgI+CbscySk+fJ3RnAg5L6v+fXEfGwpF9ImkvW/78NWJZjDTac/puxenth7drsah2ftDWre7kFf0S8DHy8wvIv5/WddpQq3Yzl4Dere75zN2W+GcssSb6OP2W+GcssSQ7+1PlmLLPkuKvHzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIM/MVOmgHToNWVKrSsys2pz8Cdm797h22ZW/xz8ZmaJcfCbmSUm1+CXtE3SM5I2S+oqLTtF0iOStpam0/KswQ7X1DR828zqXzWO+BdGxNyIaCm1VwIbIuJMYEOpPep8ErOyPXsg4tBrz55aV2Rm1VaLrp4rgPtL8/cDV+bxJT6JaWZWWd7BH0CnpI2SlpaWzYiI10rzrwMzKq0oaamkLkldPT09OZdpZpaO8Tn//E9GxA5J7wMekfR8+ZsREZKi0ooRsQZYA9DS0lLxM2ZmdvRyPeKPiB2l6S7gQWAesFPSTIDSdFce3+2TmGZmleUW/JImS2rqnwdagS1AB3Bt6WPXAr/J4/t9EtPMrLI8u3pmAA9K6v+eX0fEw5KeBNZJ+kdgO3BNjjWMro4O6OyE1lZoa6t1NWZmxyS34I+Il4GPV1i+G1iU1/fmpqMDliyB3l5Yuxba2x3+ZlZIvnN3pDo7s9CHbNrZWdt6zMyOkYN/pFpbobExm29szNpmZgWU9+Wc9aOtLevecR+/mRWcg/9otLU58M2s8NzVY2aWGAe/mVliHPxmZolx8JuZJcbBb2aWGAe/mVliFDH2RzyW1EM2rk8RnAq8UesiRpG3Z+yqp20Bb08ePhARzQMXFiL4i0RSV9ljJgvP2zN21dO2gLenmtzVY2aWGAe/mVliHPyjb02tCxhl3p6xq562Bbw9VeM+fjOzxPiI38wsMQ5+M7PEOPiPk6Rtkp6RtFlSV2nZKZIekbS1NJ1W6zpHYohtuVXSjtKyzZIuq3WdIyXpZEnrJT0v6TlJFxZ138CQ21O4/SNpTlm9myXtkXRjUffNMNszZveN+/iPk6RtQEtEvFG27PvAnyNilaSVwLSIWFGrGkdqiG25FdgXET+oVV3HStL9wP+OiJ9Kmgg0At+ggPsGhtyeGyno/gGQNA7YAXwCuJ6C7pt+A7bnK4zRfeMj/nxcAdxfmr8fuLKGtSRJ0lTgIuBnABFxMCLepKD7ZpjtKbpFwEsRsZ2C7psByrdnzHLwH78AOiVtlLS0tGxGRLxWmn8dmFGb0o5apW0BWC7paUn3FuXPb2A20AOslfSUpJ9Kmkxx981Q2wPF3D/9Pg+0l+aLum/KlW8PjNF94+A/fp+MiHOBS4HrJV1U/mZkfWlF6U+rtC2rgTOAucBrwA9rWN/RGA+cC6yOiHOA/cDK8g8UbN8MtT1F3T+UuqvagAcGvlewfQNU3J4xu28c/McpInaUpruAB4F5wE5JMwFK0121q3DkKm1LROyMiL6IeBe4h2z7iqAb6I6IJ0rt9WTBWch9wxDbU+D9A9kBxqaI2FlqF3Xf9Dtse8byvnHwHwdJkyU19c8DrcAWoAO4tvSxa4Hf1KbCkRtqW/r/I5ZcRbZ9Y15EvA78SdKc0qJFwLMUcN/A0NtT1P1TsoTDu0UKuW/KHLY9Y3nf+Kqe4yDpg2RHxpD9Kf7riPjvkqYD64D3kw0nfU1E/LlGZY7IMNvyC7I/VQPYBiwr64cd0yTNBX4KTAReJrvK4gQKtm/6DbE9/0oB90/p4OL/Ah+MiL+WlhXu/02/IbZnzP7fcfCbmSXGXT1mZolx8JuZJcbBb2aWGAe/mVliHPxmZolx8JsNQVLfgFEXV5aW3yipsexz36hdlWZHz5dzmg1B0r6IOKnC8m2UjWI61OfMxqrxtS7ArEgk/RNwGvCopDeAJ4ATJW0G/iMivijpIeBvgAbgjogYs89etTT5iN9sCJL6gGfKFn0vIv7tSEf8kk6JiD9LOhF4EvhUROyuZu1mw/ERv9nQ/l9EzD2G9f5J0lWl+b8BzgQc/DZmOPjNRpGkTwN/D1wYEb2Sfk/W5WM2ZviqHrOjtxdoKmu/LWlCaX4q8JdS6P8tcEHVqzM7Age/2dBOHHA556rS8jXAw5IeLWs/LelXwMPAeEnPAauAx6tfttnwfHLXzCwxPuI3M0uMg9/MLDEOfjOzxDj4zcwS4+A3M0uMg9/MLDEOfjOzxPx/ZnCjpFioim4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxqGLrm6OCHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9328bef0-464a-4f68-db23-e006afbfb66f"
      },
      "source": [
        "#checar a qualidade da regressao PARA TESTE\n",
        "mse=mean_squared_error(resist_obs_test,resist_calc_test)\n",
        "print(\"MSE teste=\",mse)\n",
        "R2=r2_score(resist_obs_test,resist_calc_test)\n",
        "print(\"R^2 teste=\",R2)"
      ],
      "execution_count": 1287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE teste= 10.69725682588883\n",
            "R^2 teste= 0.8531414479017505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEznkoupODnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2be107-d59b-4503-b95b-9a7db1f0f87d"
      },
      "source": [
        "#checar a qualidade da regressao PARA TREINO\n",
        "mse=mean_squared_error(resist_obs_train,resist_calc_train)\n",
        "print(\"MSE treino=\",mse)\n",
        "R2=r2_score(resist_obs_train,resist_calc_train)\n",
        "print(\"R^2 treino=\",R2)"
      ],
      "execution_count": 1288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE treino= 0.0036242406110547883\n",
            "R^2 treino= 0.9999154312149764\n"
          ]
        }
      ]
    }
  ]
}