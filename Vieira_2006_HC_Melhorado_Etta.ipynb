{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vieira_2006_HC_Melhorado_Etta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8iIUCHTIOkfeqlKJa1lfs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muriloufu/Hydrocyclone_ANN/blob/main/Vieira_2006_HC_Melhorado_Etta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOID4YHpNewq"
      },
      "source": [
        "#bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "%matplotlib inline"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHeAwtRNnC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "6c85bf90-b6e1-417c-b888-c0087b75f2b4"
      },
      "source": [
        "#selecao do dataset\n",
        "path = 'https://github.com/muriloufu/Hydrocyclone_ANN/raw/main/Tese_LG_2006_01.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "df"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>28.28</td>\n",
              "      <td>4493</td>\n",
              "      <td>65.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.30</td>\n",
              "      <td>4407</td>\n",
              "      <td>61.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>31.80</td>\n",
              "      <td>3997</td>\n",
              "      <td>72.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.20</td>\n",
              "      <td>3664</td>\n",
              "      <td>62.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>3697</td>\n",
              "      <td>54.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>10.50</td>\n",
              "      <td>3211</td>\n",
              "      <td>47.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>15.04</td>\n",
              "      <td>3257</td>\n",
              "      <td>61.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>17.16</td>\n",
              "      <td>3016</td>\n",
              "      <td>54.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>29.00</td>\n",
              "      <td>2416</td>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1789</td>\n",
              "      <td>69.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>32.68</td>\n",
              "      <td>1587</td>\n",
              "      <td>72.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>31.72</td>\n",
              "      <td>1467</td>\n",
              "      <td>63.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>11.2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1679</td>\n",
              "      <td>68.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>142</td>\n",
              "      <td>17.8</td>\n",
              "      <td>14.10</td>\n",
              "      <td>1177</td>\n",
              "      <td>59.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>11.2</td>\n",
              "      <td>16.54</td>\n",
              "      <td>1071</td>\n",
              "      <td>62.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>207</td>\n",
              "      <td>17.8</td>\n",
              "      <td>16.19</td>\n",
              "      <td>1001</td>\n",
              "      <td>56.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.61</td>\n",
              "      <td>6435</td>\n",
              "      <td>62.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.7</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1109</td>\n",
              "      <td>60.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>42.54</td>\n",
              "      <td>2866</td>\n",
              "      <td>76.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.3</td>\n",
              "      <td>10.5</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>12.43</td>\n",
              "      <td>1671</td>\n",
              "      <td>66.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>117</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.65</td>\n",
              "      <td>2744</td>\n",
              "      <td>55.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>228</td>\n",
              "      <td>14.5</td>\n",
              "      <td>20.11</td>\n",
              "      <td>1525</td>\n",
              "      <td>49.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.22</td>\n",
              "      <td>2245</td>\n",
              "      <td>63.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.96</td>\n",
              "      <td>1801</td>\n",
              "      <td>61.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.3</td>\n",
              "      <td>8.1</td>\n",
              "      <td>174</td>\n",
              "      <td>14.5</td>\n",
              "      <td>17.50</td>\n",
              "      <td>1904</td>\n",
              "      <td>62.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Di    Do    L  Teta     RL    Eu   Etta\n",
              "0   4.8   6.6  142  11.2  28.28  4493  65.18\n",
              "1   4.8   6.6  142  17.8  29.30  4407  61.76\n",
              "2   4.8   6.6  207  11.2  31.80  3997  72.47\n",
              "3   4.8   6.6  207  17.8  31.20  3664  62.23\n",
              "4   4.8   9.6  142  11.2  10.24  3697  54.06\n",
              "5   4.8   9.6  142  17.8  10.50  3211  47.30\n",
              "6   4.8   9.6  207  11.2  15.04  3257  61.52\n",
              "7   4.8   9.6  207  17.8  17.16  3016  54.30\n",
              "8   7.8   6.6  142  11.2  29.00  2416  74.59\n",
              "9   7.8   6.6  142  17.8  33.00  1789  69.00\n",
              "10  7.8   6.6  207  11.2  32.68  1587  72.32\n",
              "11  7.8   6.6  207  17.8  31.72  1467  63.40\n",
              "12  7.8   9.6  142  11.2  11.00  1679  68.82\n",
              "13  7.8   9.6  142  17.8  14.10  1177  59.83\n",
              "14  7.8   9.6  207  11.2  16.54  1071  62.42\n",
              "15  7.8   9.6  207  17.8  16.19  1001  56.44\n",
              "16  3.9   8.1  174  14.5  15.61  6435  62.84\n",
              "17  8.7   8.1  174  14.5  18.90  1109  60.35\n",
              "18  6.3   5.7  174  14.5  42.54  2866  76.73\n",
              "19  6.3  10.5  174  14.5  12.43  1671  66.00\n",
              "20  6.3   8.1  117  14.5  15.65  2744  55.61\n",
              "21  6.3   8.1  228  14.5  20.11  1525  49.17\n",
              "22  6.3   8.1  174   9.0  20.22  2245  63.44\n",
              "23  6.3   8.1  174  20.0  16.96  1801  61.14\n",
              "24  6.3   8.1  174  14.5  17.50  1904  62.74"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_18br6NreR"
      },
      "source": [
        "# funcao normatiza dados\n",
        "def Normatiza(x):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x[i].max()\n",
        "        min_x=x[i].min()\n",
        "        x[i]=2*((x[i]-min_x)/(max_x-min_x))-1\n",
        "    return x"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6NFycRWNtEI"
      },
      "source": [
        "# funcao retorna os dados a forma original - xi ISOLADO DA FUNCAO: NORMATIZA(X)\n",
        "def Original(x,x_old):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x_old[i].max()\n",
        "        min_x=x_old[i].min()\n",
        "        x[i]=((x[i]+1)/2)*(max_x-min_x)+min_x\n",
        "    return x"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRm1LcrNuMk"
      },
      "source": [
        "DAT_OLD=[] #Criar um dataframe em branco\n",
        "DAT_OLD=df.copy() #No dataframe em branco esta colocando os dados de df (dataframe que chamou no inicio)\n",
        "DAT=Normatiza(df) #No dataframe DAT coloca o dataframe df normatizado"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "iWlBoKYCCTZD",
        "outputId": "261ea900-b10d-479f-f226-6a8833320177"
      },
      "source": [
        "DAT #mostra o dataframe DAT que Ã© o df normatizado"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Di</th>\n",
              "      <th>Do</th>\n",
              "      <th>L</th>\n",
              "      <th>Teta</th>\n",
              "      <th>RL</th>\n",
              "      <th>Eu</th>\n",
              "      <th>Etta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.117028</td>\n",
              "      <td>0.285241</td>\n",
              "      <td>0.215087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.180186</td>\n",
              "      <td>0.253589</td>\n",
              "      <td>-0.017329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.334985</td>\n",
              "      <td>0.102687</td>\n",
              "      <td>0.710499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.297833</td>\n",
              "      <td>-0.019875</td>\n",
              "      <td>0.014611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.540605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.983901</td>\n",
              "      <td>-0.186603</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.702786</td>\n",
              "      <td>-0.169672</td>\n",
              "      <td>-0.033639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.571517</td>\n",
              "      <td>-0.258373</td>\n",
              "      <td>-0.524295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.161610</td>\n",
              "      <td>-0.479205</td>\n",
              "      <td>0.854570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.409288</td>\n",
              "      <td>-0.709974</td>\n",
              "      <td>0.474686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>-0.784321</td>\n",
              "      <td>0.700306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.330031</td>\n",
              "      <td>-0.828487</td>\n",
              "      <td>0.094122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.952941</td>\n",
              "      <td>-0.750460</td>\n",
              "      <td>0.462453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>-0.549550</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.760991</td>\n",
              "      <td>-0.935223</td>\n",
              "      <td>-0.148488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.609907</td>\n",
              "      <td>-0.974236</td>\n",
              "      <td>0.027523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>6.250000e-01</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.631579</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.378865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.667492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.056065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.463777</td>\n",
              "      <td>-0.960250</td>\n",
              "      <td>-0.113150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.313581</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.864396</td>\n",
              "      <td>-0.753404</td>\n",
              "      <td>0.270812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.665015</td>\n",
              "      <td>-0.358484</td>\n",
              "      <td>-0.435270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.388854</td>\n",
              "      <td>-0.807140</td>\n",
              "      <td>-0.872919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.382043</td>\n",
              "      <td>-0.542142</td>\n",
              "      <td>0.096840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.583901</td>\n",
              "      <td>-0.705558</td>\n",
              "      <td>-0.059463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-2.220446e-16</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.550464</td>\n",
              "      <td>-0.667648</td>\n",
              "      <td>0.049269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Di            Do         L  Teta        RL        Eu      Etta\n",
              "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.117028  0.285241  0.215087\n",
              "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6  0.180186  0.253589 -0.017329\n",
              "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6  0.334985  0.102687  0.710499\n",
              "3  -6.250000e-01 -6.250000e-01  0.621622   0.6  0.297833 -0.019875  0.014611\n",
              "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6 -1.000000 -0.007729 -0.540605\n",
              "5  -6.250000e-01  6.250000e-01 -0.549550   0.6 -0.983901 -0.186603 -1.000000\n",
              "6  -6.250000e-01  6.250000e-01  0.621622  -0.6 -0.702786 -0.169672 -0.033639\n",
              "7  -6.250000e-01  6.250000e-01  0.621622   0.6 -0.571517 -0.258373 -0.524295\n",
              "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6  0.161610 -0.479205  0.854570\n",
              "9   6.250000e-01 -6.250000e-01 -0.549550   0.6  0.409288 -0.709974  0.474686\n",
              "10  6.250000e-01 -6.250000e-01  0.621622  -0.6  0.389474 -0.784321  0.700306\n",
              "11  6.250000e-01 -6.250000e-01  0.621622   0.6  0.330031 -0.828487  0.094122\n",
              "12  6.250000e-01  6.250000e-01 -0.549550  -0.6 -0.952941 -0.750460  0.462453\n",
              "13  6.250000e-01  6.250000e-01 -0.549550   0.6 -0.760991 -0.935223 -0.148488\n",
              "14  6.250000e-01  6.250000e-01  0.621622  -0.6 -0.609907 -0.974236  0.027523\n",
              "15  6.250000e-01  6.250000e-01  0.621622   0.6 -0.631579 -1.000000 -0.378865\n",
              "16 -1.000000e+00 -2.220446e-16  0.027027   0.0 -0.667492  1.000000  0.056065\n",
              "17  1.000000e+00 -2.220446e-16  0.027027   0.0 -0.463777 -0.960250 -0.113150\n",
              "18  2.220446e-16 -1.000000e+00  0.027027   0.0  1.000000 -0.313581  1.000000\n",
              "19  2.220446e-16  1.000000e+00  0.027027   0.0 -0.864396 -0.753404  0.270812\n",
              "20  2.220446e-16 -2.220446e-16 -1.000000   0.0 -0.665015 -0.358484 -0.435270\n",
              "21  2.220446e-16 -2.220446e-16  1.000000   0.0 -0.388854 -0.807140 -0.872919\n",
              "22  2.220446e-16 -2.220446e-16  0.027027  -1.0 -0.382043 -0.542142  0.096840\n",
              "23  2.220446e-16 -2.220446e-16  0.027027   1.0 -0.583901 -0.705558 -0.059463\n",
              "24  2.220446e-16 -2.220446e-16  0.027027   0.0 -0.550464 -0.667648  0.049269"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHAmeF3u9b1v"
      },
      "source": [
        "#dividindo randomicamente os dados de DAT em treino e teste\n",
        "train=DAT.sample(frac=0.8,random_state=None)\n",
        "test=DAT.drop(train.index)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3NrCwW9mUU"
      },
      "source": [
        "#Definindo as variaveis independentes\n",
        "x_train=train.iloc[:,[0,1,2,3]]\n",
        "x_test=test.iloc[:,[0,1,2,3]]\n",
        "X_OLD=DAT_OLD.iloc[:,[0,1,2,3]]"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHep1do94DF",
        "outputId": "e0af3e22-6d8f-430c-d03e-153ee5d9e402"
      },
      "source": [
        "#variaveis independentes de treino e teste\n",
        "print(x_train)\n",
        "print (x_test)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Di            Do         L  Teta\n",
            "12  6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "6  -6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "16 -1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "23  2.220446e-16 -2.220446e-16  0.027027   1.0\n",
            "13  6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "10  6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "18  2.220446e-16 -1.000000e+00  0.027027   0.0\n",
            "9   6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "7  -6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "3  -6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "4  -6.250000e-01  6.250000e-01 -0.549550  -0.6\n",
            "17  1.000000e+00 -2.220446e-16  0.027027   0.0\n",
            "19  2.220446e-16  1.000000e+00  0.027027   0.0\n",
            "5  -6.250000e-01  6.250000e-01 -0.549550   0.6\n",
            "21  2.220446e-16 -2.220446e-16  1.000000   0.0\n",
            "15  6.250000e-01  6.250000e-01  0.621622   0.6\n",
            "11  6.250000e-01 -6.250000e-01  0.621622   0.6\n",
            "2  -6.250000e-01 -6.250000e-01  0.621622  -0.6\n",
            "20  2.220446e-16 -2.220446e-16 -1.000000   0.0\n",
            "0  -6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "              Di            Do         L  Teta\n",
            "1  -6.250000e-01 -6.250000e-01 -0.549550   0.6\n",
            "8   6.250000e-01 -6.250000e-01 -0.549550  -0.6\n",
            "14  6.250000e-01  6.250000e-01  0.621622  -0.6\n",
            "22  2.220446e-16 -2.220446e-16  0.027027  -1.0\n",
            "24  2.220446e-16 -2.220446e-16  0.027027   0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4vJ0_69yiE",
        "outputId": "f4225460-647f-4274-c075-3de1d0bc5e62"
      },
      "source": [
        "#definindo a variavel dependente Etta\n",
        "y_train=train.iloc[:,[6]]\n",
        "y_test=test.iloc[:,[6]]\n",
        "Y_OLD=DAT_OLD.iloc[:,[6]]\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Etta\n",
            "12  0.462453\n",
            "6  -0.033639\n",
            "16  0.056065\n",
            "23 -0.059463\n",
            "13 -0.148488\n",
            "10  0.700306\n",
            "18  1.000000\n",
            "9   0.474686\n",
            "7  -0.524295\n",
            "3   0.014611\n",
            "4  -0.540605\n",
            "17 -0.113150\n",
            "19  0.270812\n",
            "5  -1.000000\n",
            "21 -0.872919\n",
            "15 -0.378865\n",
            "11  0.094122\n",
            "2   0.710499\n",
            "20 -0.435270\n",
            "0   0.215087\n",
            "        Etta\n",
            "1  -0.017329\n",
            "8   0.854570\n",
            "14  0.027523\n",
            "22  0.096840\n",
            "24  0.049269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4haSAcEPN2S7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4799b63-1434-4e0e-93c1-19ab057f2796"
      },
      "source": [
        "#define a rede neural\n",
        "#nessa rede vao ser usados 3 camadas: Input + hidden + output\n",
        "#o numero de neuronios da output eh 1, porque tem 1 resposta (FIE)\n",
        "#o numero de neuronios na hidden eh arbitrario. O artigo fez 12 neuronios nessa camada\n",
        "#funcao de ativicao eh a logistic, segundo o artigo\n",
        "#model = MLPRegressor(random_state=1,solver='lbfgs',activation='tanh', learning_rate = 'adaptive', alpha=1e-5, \n",
        "#                     hidden_layer_sizes= tuple(12 for _ in range(5)))\n",
        "\n",
        "\n",
        "# define a rede neural \n",
        "model = Sequential()\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=1))\n",
        "model.add(Activation('linear'))\n",
        "model.compile(\n",
        "  loss='mean_squared_error',\n",
        "  optimizer='adam'\n",
        ")\n",
        "model.fit(x_train, y_train, epochs=500, batch_size=100)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.3000\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2005\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1534\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1454\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1564\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1673\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1699\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1653\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1577\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1503\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1448\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1420\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1414\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1424\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1437\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1445\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1444\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1435\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1423\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1413\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1404\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1397\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1391\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1386\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1381\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1376\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1372\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1368\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1366\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1364\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1363\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1363\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1362\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1360\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1357\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1352\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1346\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1341\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1337\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1334\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1332\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1331\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1329\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1327\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1323\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1319\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1313\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1307\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1301\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1296\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1290\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1285\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1280\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1273\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1265\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1257\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1247\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1236\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1225\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1213\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1200\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1185\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1170\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1153\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1134\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1114\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1092\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1068\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1042\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1015\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0986\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0955\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0922\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0888\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0852\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0815\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0778\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0739\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0700\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0661\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0623\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0585\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0549\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0515\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0484\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0455\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0429\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0407\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0388\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0373\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0360\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0350\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0340\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0332\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0323\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0314\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0303\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0290\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0275\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0259\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0242\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0223\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0205\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0187\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0169\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0153\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0137\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0123\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0110\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0098\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0087\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0068\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0059\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0051\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0043\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0037\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7375e-04\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3759e-04\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3993e-04\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7064e-04\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2036e-04\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8134e-04\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4798e-04\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1681e-04\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8604e-04\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5500e-04\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2397e-04\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.9371e-04\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6500e-04\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.3824e-04\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.1347e-04\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9036e-04\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6828e-04\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4645e-04\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2421e-04\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0126e-04\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7771e-04\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5399e-04\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3087e-04\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0929e-04\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0191e-05\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4248e-05\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1814e-05\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2900e-05\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7161e-05\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3983e-05\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2612e-05\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2298e-05\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2362e-05\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2262e-05\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1642e-05\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0341e-05\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8341e-05\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5730e-05\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2659e-05\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9309e-05\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5863e-05\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2472e-05\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9262e-05\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6333e-05\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3742e-05\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1517e-05\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.6574e-06\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1510e-06\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9649e-06\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0589e-06\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3884e-06\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9118e-06\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5863e-06\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3713e-06\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2298e-06\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1267e-06\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0281e-06\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9045e-06\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7351e-06\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.5099e-06\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2279e-06\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9000e-06\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5451e-06\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1867e-06\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8467e-06\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5435e-06\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2884e-06\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0842e-06\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2639e-07\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0667e-07\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1520e-07\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4285e-07\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.8257e-07\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3058e-07\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8541e-07\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4637e-07\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1349e-07\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8636e-07\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6353e-07\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4311e-07\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2342e-07\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.0330e-07\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8215e-07\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6017e-07\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3812e-07\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1686e-07\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9699e-07\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7880e-07\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6201e-07\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4627e-07\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3100e-07\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1587e-07\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0080e-07\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6062e-08\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1925e-08\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8943e-08\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7525e-08\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7982e-08\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0456e-08\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4946e-08\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1274e-08\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9178e-08\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8353e-08\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8436e-08\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9025e-08\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9803e-08\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0437e-08\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0670e-08\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0395e-08\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9593e-08\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8357e-08\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6835e-08\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5190e-08\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3563e-08\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2047e-08\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0691e-08\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.4612e-09\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.3310e-09\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2551e-09\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.2185e-09\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2322e-09\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3195e-09\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5137e-09\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8437e-09\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3250e-09\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9466e-09\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6988e-09\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5462e-09\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4508e-09\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3812e-09\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3273e-09\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2770e-09\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2162e-09\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1578e-09\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1012e-09\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0434e-09\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8898e-10\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3230e-10\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7185e-10\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0630e-10\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.3479e-10\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6130e-10\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8329e-10\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.0479e-10\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.2638e-10\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5864e-10\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9482e-10\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4320e-10\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0555e-10\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7762e-10\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5927e-10\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4736e-10\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3896e-10\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3126e-10\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2529e-10\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1934e-10\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1036e-10\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0247e-10\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3931e-11\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7637e-11\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.1548e-11\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4681e-11\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8244e-11\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.2358e-11\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7352e-11\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0798e-11\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5720e-11\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.0758e-11\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5851e-11\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1684e-11\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7661e-11\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4036e-11\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1240e-11\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8568e-11\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6812e-11\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4558e-11\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3188e-11\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2048e-11\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0631e-11\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.7197e-12\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0406e-12\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1402e-12\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5663e-12\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2412e-12\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8761e-12\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0972e-12\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1283e-12\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5729e-12\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9013e-12\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6277e-12\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3446e-12\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2818e-12\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4150e-12\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2300e-12\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4430e-12\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3222e-12\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2144e-12\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1707e-12\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0734e-12\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9684e-12\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6415e-12\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3651e-12\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1817e-12\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0769e-12\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4382e-13\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3354e-13\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2798e-13\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.5882e-13\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2522e-13\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2643e-13\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0412e-13\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4292e-13\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8263e-13\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1094e-13\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8839e-13\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1403e-13\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0772e-13\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9877e-13\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3775e-13\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8994e-13\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9003e-13\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4399e-13\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7229e-13\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5802e-13\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2950e-13\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0888e-13\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1918e-13\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0339e-13\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8022e-14\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0206e-13\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6211e-14\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5303e-14\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8274e-14\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4541e-14\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7212e-14\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5088e-14\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5884e-14\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7769e-14\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7325e-14\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9259e-14\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.3466e-14\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7407e-14\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2723e-14\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5477e-14\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7046e-14\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6444e-14\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4459e-14\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6362e-14\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6507e-14\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2289e-14\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5149e-14\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1376e-14\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6695e-14\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2999e-14\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2532e-14\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4213e-14\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2864e-14\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0170e-14\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8262e-14\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9300e-14\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3093e-14\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4586e-14\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8682e-14\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5392e-14\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1624e-14\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4836e-14\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4774e-14\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 8.7781e-15\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3896e-14\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.7669e-15\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.7004e-15\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1726e-14\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7221e-15\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5536e-15\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6990e-15\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0817e-14\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1912e-15\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1502e-14\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1648e-14\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1427e-15\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2004e-14\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3636e-14\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2249e-14\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3366e-14\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8834e-15\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4027e-15\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2009e-14\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0065e-14\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5748e-14\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5087e-14\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9.0390e-15\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2923e-15\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2053e-14\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0744e-15\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.4589e-15\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6616e-15\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2994e-15\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.2218e-14\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7976e-15\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.3634e-15\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0168e-14\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0371e-14\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3302e-14\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2329e-14\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4332e-15\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0099e-14\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1900e-14\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.8740e-15\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0915e-14\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7728e-15\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7736e-15\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.8261e-15\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2544e-14\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.1224e-15\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1695e-14\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8790e-14\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5074e-14\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.7898e-15\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0297e-14\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3330e-14\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8158e-15\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1612e-14\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1601e-14\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6597e-14\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0213e-14\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7525e-14\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3466e-14\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9121e-14\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3305e-14\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2421e-13\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3855e-14\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5665e-13\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1768e-14\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2866e-13\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3051e-13\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4738e-14\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2592e-13\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3538e-14\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1224e-13\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0640e-14\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.9816e-14\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0175e-14\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2310e-14\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5412e-14\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9397e-14\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2539e-14\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8712e-14\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.9001e-15\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4516e-14\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0673e-14\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1009e-14\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7752e-15\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.5851e-15\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0425e-14\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1053e-14\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7186e-14\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5440e-14\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.1419e-14\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9998e-14\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8711e-14\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0730e-14\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1600e-13\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7690e-14\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0476e-14\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5802e-14\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0487e-14\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1573e-14\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5354e-14\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8341e-14\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3186e-14\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3766e-14\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.5992e-14\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.0147e-14\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6622e-14\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4957e-14\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1421e-14\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8595e-14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f408a52ca10>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhi90gVN3YV"
      },
      "source": [
        "#treina a rede neural\n",
        "#model.fit(x_train, y_train)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-yOW0ZmN4e0"
      },
      "source": [
        "#usa a rede neural para treino e teste\n",
        "y_calc_train=model.predict(x_train)\n",
        "y_calc_test=model.predict(x_test)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfwjcMtN58a"
      },
      "source": [
        "#transforma a saida da rede em dataframe \n",
        "y_calc_train=pd.DataFrame(y_calc_train)\n",
        "y_calc_test=pd.DataFrame(y_calc_test)\n",
        "col_names=list(y_train)\n",
        "y_calc_train.columns = col_names\n",
        "y_calc_test.columns = col_names"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RboALKIN7as"
      },
      "source": [
        "#Desnormatizar os dados obtidos da rede neural\n",
        "y_calc_train=Original(y_calc_train,Y_OLD)\n",
        "y_calc_test=Original(y_calc_test,Y_OLD)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjoCPU8bN92O"
      },
      "source": [
        "#recupera os dados originais \n",
        "test=[]\n",
        "train=[]\n",
        "train=Original(y_train,Y_OLD)\n",
        "test=Original(y_test,Y_OLD)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiL9upNxN_RT"
      },
      "source": [
        "#Resposta para fazer o grafico (Etta-treino)\n",
        "resist_obs_train=[]\n",
        "resist_calc_train=[]\n",
        "resist_calc_train=y_calc_train['Etta'].copy()\n",
        "resist_obs_train=train['Etta'].copy()"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_g9O8DOAfQ"
      },
      "source": [
        "#Resposta para fazer o grafico (Etta-teste)\n",
        "resist_obs_test=[]\n",
        "resist_calc_test=[]\n",
        "resist_calc_test=y_calc_test['Etta'].copy()\n",
        "resist_obs_test=test['Etta'].copy()"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHCXQdoOBtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "6fda773b-62b0-49bd-c37d-22736e711307"
      },
      "source": [
        "#expressa os dois dados em figura - ETTA\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.scatter(resist_obs_test,resist_calc_test, s=10, c='b', marker=\"s\", label='teste')\n",
        "ax1.scatter(resist_obs_train,resist_calc_train, s=10, c='r', marker=\"o\", label='treino')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylabel('Etta Calculado')\n",
        "plt.xlabel('Etta Observado')\n",
        "plt.show()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxqGLrm6OCHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2638d029-b532-4444-ea85-2d12b874c801"
      },
      "source": [
        "#checar a qualidade da regressao PARA TESTE\n",
        "mse=mean_squared_error(resist_obs_test,resist_calc_test)\n",
        "print(\"MSE teste=\",mse)\n",
        "R2=r2_score(resist_obs_test,resist_calc_test)\n",
        "print(\"R^2 teste=\",R2)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE teste= 3.593125849299922\n",
            "R^2 teste= 0.8460037882984156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEznkoupODnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291fc8fe-c202-437c-a842-d7b7a7d2e739"
      },
      "source": [
        "#checar a qualidade da regressao PARA TREINO\n",
        "mse=mean_squared_error(resist_obs_train,resist_calc_train)\n",
        "print(\"MSE treino=\",mse)\n",
        "R2=r2_score(resist_obs_train,resist_calc_train)\n",
        "print(\"R^2 treino=\",R2)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE treino= 7.201451806665948e-12\n",
            "R^2 treino= 0.9999999999998738\n"
          ]
        }
      ]
    }
  ]
}